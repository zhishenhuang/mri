{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8500973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import torch\n",
    "import torch.fft as F\n",
    "from importlib import reload\n",
    "from torch.nn.functional import relu\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Func\n",
    "import torch.optim as optim\n",
    "import utils,mask_backward_new\n",
    "import matplotlib.pyplot as plt\n",
    "# from maskbackward import mask_backward\n",
    "from mask_backward_new import mask_backward, mask_eval\n",
    "from utils import mask_complete , mask_makebinary,kplot, mask_filter\n",
    "from utils import get_x_f_from_yfull,mask_naiveRand, apply_mask, sigmoid_binarize\n",
    "\n",
    "sys.path.insert(0,'/home/huangz78/mri/unet/')\n",
    "from unet_model import UNet\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2169b502",
   "metadata": {},
   "source": [
    "#### import data to test mask_backward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f0c9d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_gt = np.load('/home/huangz78/data/data_gt.npz')\n",
    "# datafornn = np.load('/home/huangz78/data/datafornn.npz')\n",
    "data = np.load('/home/huangz78/data/traindata_x.npz')\n",
    "dtyp = torch.float\n",
    "xfull = torch.tensor(data['xfull'],dtype=dtyp)\n",
    "fullmask = torch.tensor(data['mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3ab636a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNet loaded successfully from: /home/huangz78/checkpoints/mnet.pth\n",
      "Unet loaded successfully from: /home/huangz78/checkpoints/unet_1.pth\n",
      "nn's are ready\n"
     ]
    }
   ],
   "source": [
    "# load a mnet\n",
    "from mnet import MNet\n",
    "# mnet = MNet(out_size=320-24)\n",
    "mnet = MNet(beta=1,in_channels=2,out_size=320-24, imgsize=(320,320),poolk=3)\n",
    "checkpoint = torch.load('/home/huangz78/checkpoints/mnet.pth')\n",
    "mnet.load_state_dict(checkpoint['model_state_dict'])\n",
    "print('MNet loaded successfully from: ' + '/home/huangz78/checkpoints/mnet.pth')\n",
    "mnet.eval()\n",
    "# load a unet for maskbackward\n",
    "UNET =  UNet(n_channels=1,n_classes=1,bilinear=True,skip=False)\n",
    "checkpoint = torch.load('/home/huangz78/checkpoints/unet_'+ str(UNET.n_channels) +'.pth')\n",
    "UNET.load_state_dict(checkpoint['model_state_dict'])\n",
    "print('Unet loaded successfully from: ' + '/home/huangz78/checkpoints/unet_'+ str(UNET.n_channels) +'.pth' )\n",
    "UNET.train()\n",
    "print('nn\\'s are ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fa05ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload(utils)\n",
    "# from utils import sigmoid_binarize\n",
    "reload(mask_backward_new)\n",
    "from mask_backward_new import mask_backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73e9aafb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 1, upper level loss: 0.09510967135429382\n",
      " changed rows in this batch: 0.0, loss of current mask: 10.1144939661026%\n",
      "samp. ratio: 0.30875, Recon. rel. err: 0.08818173408508301 \n",
      "\n",
      "No change in row selections after 7 iters, ending iteration~\n",
      "\n",
      "return at Iter ind:  6\n",
      "loss of returned mask: 8.469775319099426%\n",
      "samp. ratio: 0.30875, Recon. rel. err: 0.034721843898296356 \n",
      "\n",
      "iter: 1, upper level loss: 0.09165935218334198\n",
      " changed rows in this batch: 0.0, loss of current mask: 10.788413137197495%\n",
      "samp. ratio: 0.30875, Recon. rel. err: 0.08469775319099426 \n",
      "\n",
      "No change in row selections after 7 iters, ending iteration~\n",
      "\n",
      "return at Iter ind:  6\n",
      "loss of returned mask: 8.65919217467308%\n",
      "samp. ratio: 0.30875, Recon. rel. err: 0.040159519761800766 \n",
      "\n",
      "iter: 1, upper level loss: 0.09389011561870575\n",
      " changed rows in this batch: 0.0, loss of current mask: 10.457146912813187%\n",
      "samp. ratio: 0.30875, Recon. rel. err: 0.0865919217467308 \n",
      "\n",
      "No change in row selections after 7 iters, ending iteration~\n",
      "\n",
      "return at Iter ind:  6\n",
      "loss of returned mask: 8.400752395391464%\n",
      "samp. ratio: 0.30875, Recon. rel. err: 0.037078991532325745 \n",
      "\n",
      "iter: 1, upper level loss: 0.09467171877622604\n",
      " changed rows in this batch: 0.0, loss of current mask: 10.289300233125687%\n",
      "samp. ratio: 0.30875, Recon. rel. err: 0.08400752395391464 \n",
      "\n",
      "No change in row selections after 7 iters, ending iteration~\n",
      "\n",
      "return at Iter ind:  6\n",
      "loss of returned mask: 8.774181455373764%\n",
      "samp. ratio: 0.30875, Recon. rel. err: 0.03796315938234329 \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-a0de64cb20e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m                       \u001b[0mmaxIter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxIter_mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbreak_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxIter_mb\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                       \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr_mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'UNET'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbudget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbudget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                       verbose=True,dtyp=torch.float,testmode=True)\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mind\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mri/mask_backward_new.py\u001b[0m in \u001b[0;36mmask_backward\u001b[0;34m(highmask, xstar, maxIter, seed, eps, normalize, budget, lr, weight_decay, momentum, beta, alpha, c, unet_mode, unet, mnet, unroll_block, Lambda, rho, mode, lr_Lambda, break_limit, print_every, verbose, save_cp, dtyp, testmode)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0mfullmask_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_makebinary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfullmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/pyenv/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/pyenv/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batchsize = 5\n",
    "xstar = xfull[0:batchsize,:,:]\n",
    "\n",
    "corefreq = 24\n",
    "yfull = torch.fft.fftshift(F.fftn(xstar,dim=(1,2),norm='ortho')) # y is ROLLED!\n",
    "lowfreqmask,_,_ = mask_naiveRand(xstar.shape[1],fix=corefreq,other=0,roll=True)\n",
    "\n",
    "z        = apply_mask(lowfreqmask,yfull)\n",
    "highmask = sigmoid_binarize(mnet(z))\n",
    "# x_lf     = get_x_f_from_yfull(lowfreqmask,yfull)\n",
    "# highmask = sigmoid_binarize(mnet(x_lf.view(batchsize,1,xstar.shape[1],xstar.shape[2])))\n",
    "\n",
    "NN    = 8\n",
    "alpha_grid = 10**(np.linspace(-6,-1,NN))\n",
    "maskloss = np.zeros((NN))\n",
    "sparsity = np.zeros((NN))\n",
    "########################################  \n",
    "## (1) mask_backward\n",
    "########################################    \n",
    "maxIter_mb = 10; lr_mb = 1e-2; \n",
    "budget = 56\n",
    "# alpha = 1e-5\n",
    "c = 1e-2\n",
    "ind = 0\n",
    "for alpha in alpha_grid:\n",
    "    # load a unet for maskbackward\n",
    "    UNET =  UNet(n_channels=1,n_classes=1,bilinear=True,skip=False)\n",
    "    checkpoint = torch.load('/home/huangz78/checkpoints/unet_'+ str(UNET.n_channels) +'.pth')\n",
    "    UNET.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print('Unet loaded successfully from: ' + '/home/huangz78/checkpoints/unet_'+ str(UNET.n_channels) +'.pth' )\n",
    "    UNET.train()\n",
    "    print('nn\\'s are ready')\n",
    "# highmask_refined,unet = mask_backward(highmask,xstar,unet=UNET, mnet=mnet,\\\n",
    "#                   beta=1.,alpha=alpha,c=c,\\\n",
    "#                   maxIter=maxIter_mb,seed=0,break_limit=maxIter_mb*3//5,\\\n",
    "#                   lr=lr_mb,mode='UNET',budget=budget,normalize=False,\\\n",
    "#                   verbose=True,dtyp=torch.float)\n",
    "    maskloss[ind],sparsity[ind] = mask_backward(highmask,xstar,unet=UNET, mnet=mnet,\\\n",
    "                      beta=1.,alpha=alpha,c=c,\\\n",
    "                      maxIter=maxIter_mb,seed=0,break_limit=maxIter_mb*3//5,\\\n",
    "                      lr=lr_mb,mode='UNET',budget=budget,normalize=False,\\\n",
    "                      verbose=True,dtyp=torch.float,testmode=True)\n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3356de9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(alpha,maskloss)\n",
    "plt.title('mask loss')\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(alpha,sparsity,label='actual')\n",
    "plt.plot(alpha,(corefreq+budget)/320,label='target')\n",
    "plt.title('mask sparsity')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1061b992",
   "metadata": {},
   "outputs": [],
   "source": [
    "(highmask_refined - highmask).abs().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14c7c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 0\n",
    "highmask_refined[ind,:] - highmask[ind,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8355d2ac",
   "metadata": {},
   "source": [
    "### old tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c01bf42",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_gt = np.load('/home/huangz78/data/data_gt.npz')\n",
    "picind = np.random.randint(199)\n",
    "xstar = data_gt['imgdata'][:,:,27]\n",
    "xstar = xstar/np.max(np.abs(xstar))\n",
    "# highmask = datafornn['labels'][picind,:]\n",
    "plt.figure()\n",
    "plt.imshow(xstar)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abef492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload(maskbackward)\n",
    "# from maskbackward import mask_backward\n",
    "\n",
    "#mode UNET:\n",
    "\n",
    "reload(mask_backward_new)\n",
    "from mask_backward_new import mask_backward,mask_eval\n",
    "\n",
    "dtyp = torch.float\n",
    "# unroll_block = 8; Lambda=6.1e-4; rho=1e1\n",
    "\n",
    "# base = .05; expand = .15\n",
    "# highmask = torch.zeros((round(320*(1-base))),dtype=torch.double)\n",
    "# highmask[np.random.choice(round(320*(1-base)),round(320*expand),replace=False)] = 1\n",
    "\n",
    "highmask = mask_filter(fullmask,base=round(320*0.05),roll=True)\n",
    "print(highmask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072abd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = 1\n",
    "UNET =  UNet(n_channels=n_channels,n_classes=n_channels,bilinear=True,skip=False)\n",
    "checkpoint = torch.load('/home/huangz78/checkpoints/unet_' + str(n_channels) + '.pth')\n",
    "UNET.load_state_dict(checkpoint['model_state_dict'])\n",
    "UNET.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66705874",
   "metadata": {},
   "outputs": [],
   "source": [
    "## quick comparison between ifft recon and unet recon\n",
    "imgHeg = 320; imgWid = 320\n",
    "fullmask = torch.tensor( mask_complete(highmask,imgHeg,dtyp=torch.float) )\n",
    "kplot(fullmask)\n",
    "print('sparsity of fullmask = ',fullmask.sum().item()/imgHeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee6f294",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xstar = torch.tensor(xstar,dtype=dtyp)\n",
    "DTyp = torch.cfloat if dtyp==torch.float else torch.cdouble\n",
    "y = torch.fft.fftshift(F.fftn(xstar,dim=(0,1),norm='ortho'))\n",
    "z = torch.fft.ifftshift(torch.tensordot(torch.diag(fullmask).to(DTyp),y,dims=([1],[0])))\n",
    "kplot(y,roll=False,log=True)\n",
    "kplot(z,roll=True,log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20eb465",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgHeg = 320; imgWid = 320\n",
    "x_ifft = torch.abs(F.ifftn(z,dim=(0,1),norm='ortho')).to(dtyp)\n",
    "x_unet = UNET(x_ifft.view(1,1,imgHeg,imgWid)).detach()\n",
    "\n",
    "print('error of x_ifft = ', torch.norm(torch.flatten(x_ifft)-torch.flatten(xstar),'fro')/torch.norm(xstar,'fro') )\n",
    "print('error of x_unet = ', torch.norm(torch.flatten(x_unet)-torch.flatten(xstar),'fro')/torch.norm(xstar,'fro') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5675b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sigpy.mri.app import TotalVariationRecon\n",
    "NN = 50\n",
    "Lambda_grid = 10**np.linspace(-3.5,-3,NN)\n",
    "errRec = np.zeros((NN))\n",
    "ind = 1\n",
    "\n",
    "mps  = np.ones((1,imgHeg,imgWid))\n",
    "y_sp = np.reshape(z.numpy(),(-1,imgHeg,imgWid))\n",
    "for Lambda in Lambda_grid:\n",
    "# Lambda = 10**(-6.31) \n",
    "# Lambda = 10**(-3.2755) # np.log10(Lambda_grid[np.argmin(errRec)])\n",
    "    print('{} out of {}'.format(ind,NN))\n",
    "    x_sp = np.fft.fftshift( np.abs(TotalVariationRecon(y_sp, mps, Lambda,show_pbar=False).run()) ) \n",
    "    x_sp = torch.tensor(x_sp)\n",
    "    errRec[ind-1] = torch.norm(torch.flatten(x_sp)-torch.flatten(xstar),'fro')/torch.norm(xstar,'fro')\n",
    "    ind += 1\n",
    "#     print('error of x_sp = ', torch.norm(torch.flatten(x_sp)-torch.flatten(xstar),'fro')/torch.norm(xstar,'fro'))\n",
    "\n",
    "plt.figure()\n",
    "plt.xscale('log')\n",
    "plt.plot(Lambda_grid,errRec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80167b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.linspace(-6,-4,gridnum)[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb64834",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reload(mask_backward_new)\n",
    "from mask_backward_new import mask_backward,mask_eval\n",
    "\n",
    "maxIter = 200\n",
    "gridnum = 10\n",
    "alpha_grid = 10**np.linspace(-4.6,-4.5,gridnum)\n",
    "sr_rec = np.zeros((gridnum))\n",
    "mloss_rec = np.zeros(gridnum)\n",
    "\n",
    "ind = 0\n",
    "for alpha in alpha_grid:\n",
    "    print('[{}/{}]  alpha {}'.format(ind+1,gridnum,alpha))\n",
    "    highmask_refined,refine_mloss,init_loss = mask_backward(highmask,xstar,\\\n",
    "                          beta=1., alpha=alpha,maxIter=maxIter,seed=0,break_limit=maxIter//2,\\\n",
    "                          lr=5e-4,mode='UNET',\\\n",
    "                          verbose=False,dtyp=dtyp)\n",
    "    print('Difference between masks: \\n',highmask_refined - highmask)\n",
    "#     print('Refined mask is: \\n',highmask_refined)\n",
    "    mloss_rec[ind] = refine_mloss\n",
    "    sr_rec[ind] = (torch.sum(highmask_refined).item() + 24)/320\n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b9b7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(alpha_grid,mloss_rec,label='refined')\n",
    "plt.scatter(alpha_grid,init_loss*np.ones(mloss_rec.shape),label='init.')\n",
    "plt.title('mask loss')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(alpha_grid,sr_rec,label='refined')\n",
    "plt.scatter(alpha_grid,0.25*np.ones(mloss_rec.shape),label='init.')\n",
    "plt.title('mask sampling ratio')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae7f844",
   "metadata": {},
   "source": [
    "### arXiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752768c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(mask_backward_new)\n",
    "from mask_backward_new import mask_backward\n",
    "\n",
    "# mode ADMM:\n",
    "\n",
    "highmask = torch.zeros((round(320*0.9)))\n",
    "highmask[np.random.choice(round(320*0.9),int(320*.1),replace=False)] = 1\n",
    "\n",
    "naive_mloss = mask_eval(mask_complete(highmask.to(torch.double),320),xstar,unroll_block=unroll_block,Lambda=Lambda,rho=rho) * 100\n",
    "highmask_refined,refine_mloss = mask_backward(highmask,xstar,\\\n",
    "                          beta=1., alpha=1e1,maxIter=200,unroll_block=unroll_block,seed=0,break_limit=100,\\\n",
    "                          lr=5e-4,mode='ADMM',Lambda=Lambda,rho=rho,\\\n",
    "                          verbose=True,perturb=False,perturb_freq=5,eps=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89e95ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vary sampling ratio, observe RMSE for the same image.\n",
    "reload(mask_backward_new)\n",
    "from mask_backward_new import mask_backward\n",
    "\n",
    "base=0.1\n",
    "r_grid = np.array([0.1,0.15,0.2])\n",
    "naive_mloss = np.zeros((r_grid.size))\n",
    "refine_mloss = np.zeros((r_grid.size))\n",
    "\n",
    "sampRatio = np.zeros((r_grid.size))\n",
    "\n",
    "unroll_block = 6; Lambda=6.1e-4; rho=1e1; lr = 5e-2\n",
    "maxIter = 300; break_limit = round(maxIter/3)\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "ind = 0\n",
    "for r in r_grid:\n",
    "    print('\\n r {}, the {} item out of {}'.format(r,ind+1,r_grid.size))\n",
    "    highmask = torch.zeros((round(320*(1-base))))\n",
    "    highmask[np.random.choice(round(320*(1-base)),int(320*r),replace=False)] = 1\n",
    "    \n",
    "    naive_mloss[ind] = mask_eval(mask_complete(highmask.to(torch.double),320),xstar,unroll_block=unroll_block,Lambda=Lambda,rho=rho) * 100\n",
    "    highmask_refined,refine_mloss[ind] = mask_backward(highmask,xstar,seed=0,\\\n",
    "                              beta=1., alpha=9.5e0,maxIter=maxIter,unroll_block=unroll_block,break_limit=break_limit,\\\n",
    "                              lr=lr,mode='ADMM',Lambda=Lambda,rho=rho,\\\n",
    "                              verbose=True,perturb=False,perturb_freq=5,eps=1e-2)\n",
    "    sampRatio[ind] = (highmask_refined.sum().item() + round(320*0.1))/320\n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c72e53e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('sampRatio: ',sampRatio)\n",
    "plt.figure()\n",
    "plt.scatter(r_grid,naive_mloss,label='naive')\n",
    "plt.scatter(sampRatio,refine_mloss,label='refined')\n",
    "plt.legend(bbox_to_anchor=(1.04,0.5), loc=\"center left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b27586e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## find a good alpha for l1 penalty\n",
    "reload(mask_backward_new); reload(utils);\n",
    "from mask_backward_new import mask_backward\n",
    "alpha_grid = np.linspace(1,10,10)\n",
    "sparsity_ = np.zeros(alpha_grid.size)\n",
    "change_count = np.zeros(alpha_grid.size)\n",
    "\n",
    "unroll_block = 6; Lambda=6.1e-4; rho=1e1; lr = 5e-2\n",
    "maxIter = 300; break_limit = round(maxIter/2)\n",
    "# add samp. ratio. = .1 ---> best alpha = ?\n",
    "# add samp. ratio. = .2 ---> best alpha = ?\n",
    "# add samp. ratio. = .2 ---> best alpha = ?\n",
    "\n",
    "base = 0.05\n",
    "additional = 0.125\n",
    "\n",
    "highmask = torch.zeros((round(320*(1-base))))\n",
    "highmask[np.random.choice(round(320*(1-base)),round(320*additional),replace=False)] = 1\n",
    "\n",
    "ind = 0\n",
    "for alpha in alpha_grid:\n",
    "    print('\\n\\talpha = {}'.format(alpha))\n",
    "    highmask_refined,_ = mask_backward(highmask,xstar,\\\n",
    "                  beta=1, alpha=alpha,maxIter=maxIter,unroll_block=unroll_block,seed=0,break_limit=break_limit,\\\n",
    "                  lr=lr,mode='ADMM',Lambda=Lambda,rho=rho,\\\n",
    "                  perturb=False,perturb_freq=10,verbose=True)\n",
    "    sparsity_[ind] = mask_complete(highmask_refined.to(torch.double),320).sum().item()/320\n",
    "    change_count[ind] = torch.abs(highmask_refined - highmask).sum().item()\n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818f7fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(alpha_grid,sparsity_,label='end')\n",
    "plt.scatter(alpha_grid,(base+additional)*np.ones(alpha_grid.size),label='start')\n",
    "plt.title('sparsity')\n",
    "# plt.xscale('log')\n",
    "plt.legend(bbox_to_anchor=(1.04,0.5), loc=\"center left\")\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(alpha_grid,change_count)\n",
    "# plt.xscale('log')\n",
    "plt.title('change count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734e6e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_mloss = mask_eval(mask_complete(highmask,imgHeg,dtyp=dtyp),xstar,mode='UNET',UNET=UNET,dtyp=dtyp) * 100\n",
    "print('naive mask loss = ',naive_mloss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
