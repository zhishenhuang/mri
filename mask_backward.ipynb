{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851fcda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import torch\n",
    "import torch.fft as F\n",
    "from importlib import reload\n",
    "from torch.nn.functional import relu\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Func\n",
    "import torch.optim as optim\n",
    "import utils\n",
    "import mask_backward_v4\n",
    "import matplotlib.pyplot as plt\n",
    "from mask_backward_v4 import mask_backward, mask_eval\n",
    "from utils import *\n",
    "from mnet.mnet_v2 import MNet\n",
    "# sys.path.insert(0,'/home/huangz78/mri/unet/')\n",
    "from unet.unet_model import UNet\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68672fe3",
   "metadata": {},
   "source": [
    "#### import data to test mask_backward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abafc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_gt = np.load('/home/huangz78/data/data_gt.npz')\n",
    "# data = np.load('/home/huangz78/data/traindata_x.npz')\n",
    "# xfull = torch.tensor(data['xfull'],dtype=dtyp)\n",
    "# fullmask = torch.tensor(data['mask']) # a random mask\n",
    "\n",
    "dtyp = torch.float\n",
    "datafornn = np.load('/mnt/shared_a/fastMRI/knee_singlecoil_val.npz')['data']\n",
    "xfull = torch.tensor(datafornn,dtype=dtyp)\n",
    "\n",
    "# shuffle_inds = torch.randperm(xfull.shape[0])\n",
    "# xfull = xfull[shuffle_inds,:,:]\n",
    "print(xfull.shape)\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbc1438",
   "metadata": {},
   "source": [
    "# 8-fold check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb42a57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corefreq = 8\n",
    "budget   = 32\n",
    "\n",
    "mnet = MNet(beta=1,in_chans=2,out_size=320-corefreq, imgsize=(320,320),poolk=3).to(device)\n",
    "# mnet.apply(weights_init)\n",
    "mnet.eval()\n",
    "print('mnet is randomly initialized by PyTorch default setting~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4ea148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batchind = 3\n",
    "# batchsize = 5\n",
    "# batch = torch.arange((batchind-1)*batchsize,batchind*batchsize,1)\n",
    "# print(shuffle_inds[batch])\n",
    "# batch = torch.tensor([7022, 11548,  4056, 11480,  3944])\n",
    "batch = torch.tensor([0,400,100,200,300])\n",
    "xstar = xfull[batch,:,:].to(device)\n",
    "\n",
    "for ind in range(xstar.shape[0]):\n",
    "    xstar[ind,:,:] = xstar[ind,:,:]/xstar[ind,:,:].max()\n",
    "\n",
    "# NN         = 21\n",
    "# alpha_grid = 10**(np.array([-4,-3.5,-3,-2.5,-2]))\n",
    "# alpha_grid = 10**torch.arange(-5.5,-3.91,.1)\n",
    "alpha_grid = np.array([0])\n",
    "c_grid     = np.array([0])\n",
    "# c_grid     = np.array([1e-4,1e-3,1e-2])\n",
    "print('alpha grid: ',alpha_grid)\n",
    "print('c     grid: ',c_grid)\n",
    "l2loss   = np.zeros((len(alpha_grid),len(c_grid)))\n",
    "hfen     = np.zeros((len(alpha_grid),len(c_grid)))\n",
    "sparsity = np.zeros((len(alpha_grid),len(c_grid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1622b007",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowfreqmask = mask_naiveRand(xstar.shape[1],fix=corefreq,other=0,roll=True)[0]\n",
    "\n",
    "yfull = torch.fft.fftshift(F.fftn(xstar,dim=(1,2),norm='ortho'),dim=(1,2)) # y is ROLLED!\n",
    "y = torch.zeros((yfull.shape[0],2,yfull.shape[1],yfull.shape[2]),dtype=torch.float,device=device)\n",
    "y[:,0,lowfreqmask==1,:] = torch.real(yfull)[:,lowfreqmask==1,:]\n",
    "y[:,1,lowfreqmask==1,:] = torch.imag(yfull)[:,lowfreqmask==1,:]\n",
    "\n",
    "highmask = mnet(y).detach()\n",
    "highmask = torch.sigmoid( mnet(y) ).detach()\n",
    "highmask = mask_makebinary(raw_normalize(highmask,budget,threshold=0.5,device=device),\n",
    "                           threshold=0.5,sigma=False,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6580ddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "highmask_view = mask_makebinary(raw_normalize(torch.sigmoid(highmask),budget,threshold=0.5),threshold=0.5,sigma=False)\n",
    "fullmask      = mask_complete(highmask_view,320)\n",
    "kplot(fullmask[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee099b4d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# highmask = mask_filter(mask_naiveRand(320,fix=corefreq,other=1.5*budget,roll=True)[0],base=corefreq,roll=True)\n",
    "# highmask = highmask.repeat(5,1)\n",
    "\n",
    "maxIter_mb = 100\n",
    "lr_mb      = 1e-1 # 1e-1\n",
    "lr_u       = 1e-3 # 1e-3 # what actually influences the performance\n",
    "unet_skip  = True\n",
    "print('lr_mb = ', lr_mb)\n",
    "print('lr_u  = ', lr_u)\n",
    "\n",
    "c_ind = 0\n",
    "for c in c_grid:\n",
    "    print(f'c_ind {c_ind+1} out of {len(c_grid)}')\n",
    "    a_ind = 0\n",
    "    for alpha in alpha_grid:\n",
    "        print(f'alpha_ind {a_ind+1} out of {len(alpha_grid)}')\n",
    "        ### load a unet for maskbackward\n",
    "#         UNET = UNet(n_channels=2,n_classes=1,bilinear=(not unet_skip),skip=unet_skip)\n",
    "#         unetpath = '/home/huangz78/checkpoints/unet_2_'+str(unet_skip)+'_rand'+'.pt'\n",
    "        UNET = UNet(in_chans=1,n_classes=1,bilinear=(not unet_skip),skip=unet_skip).to(device)\n",
    "        unetpath = '/mnt/shared_a/checkpoints/leo/mri/unet_1_'+str(unet_skip)+'_8frand'+'.pt'\n",
    "        checkpoint = torch.load(unetpath)\n",
    "        UNET.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print('Unet loaded successfully from: ' + unetpath )\n",
    "        UNET.train()\n",
    "        (l2loss[a_ind,c_ind],hfen[a_ind,c_ind]),sparsity[a_ind,c_ind] =\\\n",
    "                        mask_backward(highmask.to(device),xstar.to(device),unet=UNET, mnet=mnet.to(device),\\\n",
    "                          beta=1.,alpha=alpha,c=c,\\\n",
    "                          maxIter=maxIter_mb,seed=0,break_limit=np.inf,\\\n",
    "                          lr=lr_mb,lru=lr_u,\\\n",
    "                          mode='UNET',budget=budget,normalize=True,\\\n",
    "                          dtyp=torch.float,verbose=True,testmode='sigpy',hfen=True,\\\n",
    "                          return_loss_only=True,save_cp=False,device=device)\n",
    "        a_ind += 1\n",
    "    print('\\n')\n",
    "    c_ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794a7113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# highmask = sigmoid_binarize(raw_normalize(mnet(z),budget=budget))\n",
    "randmask = torch.zeros(highmask.shape)\n",
    "for ind in range(highmask.shape[0]):\n",
    "    sampinds = np.random.choice(highmask.shape[1],budget,replace=False)\n",
    "    randmask[ind,sampinds] = 1\n",
    "lowfmask,_,_ = mask_naiveRand(xstar.shape[1]-corefreq,fix=budget,other=0,roll=True)\n",
    "lowfmask = lowfmask.repeat(highmask.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c14643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_highmask = mask_complete(highmask,320)\n",
    "full_randmask = mask_complete(randmask,320)\n",
    "full_lowfmask = mask_complete(lowfmask,320)\n",
    "\n",
    "(rand_l2,rand_hfen) = mask_eval(full_randmask,xstar,mode='sigpy',hfen=True)\n",
    "(lowf_l2,lowf_hfen) = mask_eval(full_lowfmask,xstar,mode='sigpy',hfen=True)\n",
    "# (gred_l2,gred_hfen) = mask_eval(full_gredmask.to(torch.float),xstar,mode='sigpy',hfen=True)\n",
    "print('mode = sigpy')\n",
    "\n",
    "print(rand_l2)\n",
    "print(lowf_l2)\n",
    "# print(gred_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ff8a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.log10(alpha_grid[4]))\n",
    "print(10**(alpha_grid[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17415928",
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = ['H', 'D', 'P', 'X','+']\n",
    "plt.figure(figsize=(10,8))\n",
    "for c_ind in range(len(c_grid)):\n",
    "    plt.plot(alpha_grid,l2loss[:,c_ind],label='c='+str(c_grid[c_ind]),marker=markers[c_ind],markersize=7)\n",
    "plt.plot(alpha_grid,np.ones(alpha_grid.shape)*rand_l2,color='r',label='rand',linestyle = 'dotted')\n",
    "plt.plot(alpha_grid,np.ones(alpha_grid.shape)*lowf_l2,color='g',label='low freq.',linestyle = 'dotted')\n",
    "plt.title('l2 loss of masks')\n",
    "plt.xlabel('alpha')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "for c_ind in range(len(c_grid)):\n",
    "    plt.plot(alpha_grid,hfen[:,c_ind],label='c='+str(c_grid[c_ind]),marker=markers[c_ind],markersize=7)\n",
    "plt.plot(alpha_grid,np.ones(alpha_grid.shape)*rand_hfen,color='r',label='rand',linestyle = 'dotted')\n",
    "plt.plot(alpha_grid,np.ones(alpha_grid.shape)*lowf_hfen,color='g',label='low freq.',linestyle = 'dotted')\n",
    "plt.title('HFEN of masks')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "for c_ind in range(len(c_grid)):\n",
    "    plt.plot(alpha_grid,sparsity[:,c_ind],label='c='+str(c_grid[c_ind]),marker=markers[c_ind],markersize=7)\n",
    "plt.plot(alpha_grid,(corefreq+budget)/320*np.ones(alpha_grid.shape),'-.',label='target')\n",
    "plt.title('mask sparsity')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('alpha')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8702d1",
   "metadata": {},
   "source": [
    "# 4-fold check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a8fe8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corefreq = 16\n",
    "budget   = 64\n",
    "from mnet import MNet\n",
    "mnet = MNet(beta=1,in_channels=2,out_size=320-corefreq, imgsize=(320,320),poolk=3)\n",
    "mnet.apply(weights_init)\n",
    "mnet.eval()\n",
    "print('mnet is initialized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ccedee",
   "metadata": {},
   "outputs": [],
   "source": [
    "xstar = xfull[0:5,:,:]\n",
    "for ind in range(xstar.shape[0]):\n",
    "    xstar[ind,:,:] = xstar[ind,:,:]/xstar[ind,:,:].max()\n",
    "\n",
    "NN         = 11\n",
    "alpha_grid = 10**(np.linspace(-4.5,-3.5,NN))\n",
    "c_grid     = np.array([1e-4,1e-3,1e-2,1e-1])\n",
    "\n",
    "l2loss   = np.zeros((NN,5))\n",
    "hfen     = np.zeros((NN,5))\n",
    "sparsity = np.zeros((NN,5))\n",
    "\n",
    "maxIter_mb = 30\n",
    "lr_mb      = 1e-2\n",
    "\n",
    "unet_skip = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cd9068",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "highmask = mask_filter(mask_naiveRand(320,fix=corefreq,other=1.5*budget,roll=True)[0],base=corefreq,roll=True)\n",
    "highmask = highmask.repeat(5,1)\n",
    "\n",
    "c_ind = 0\n",
    "for c in c_grid:\n",
    "    print(f'c_ind {c_ind+1} out of {len(c_grid)}')\n",
    "    a_ind = 0\n",
    "    for alpha in alpha_grid:\n",
    "        print(f'alpha_ind {a_ind+1} out of {len(alpha_grid)}')\n",
    "        # load a unet for maskbackward\n",
    "        UNET = UNet(n_channels=1,n_classes=1,bilinear=True,skip=False)\n",
    "        unetpath = '/home/huangz78/checkpoints/unet_1_False.pth'\n",
    "        checkpoint = torch.load(unetpath)\n",
    "        UNET.load_state_dict(checkpoint['model_state_dict'])\n",
    "        UNET.train()\n",
    "    # highmask_refined,unet = mask_backward(highmask,xstar,unet=UNET, mnet=mnet,\\\n",
    "    #                   beta=1.,alpha=alpha,c=c,\\\n",
    "    #                   maxIter=maxIter_mb,seed=0,break_limit=maxIter_mb*3//5,\\\n",
    "    #                   lr=lr_mb,mode='UNET',budget=budget,normalize=False,\\\n",
    "    #                   verbose=True,dtyp=torch.float)\n",
    "        (l2loss[a_ind,c_ind],hfen[a_ind,c_ind]),sparsity[a_ind,c_ind] =\\\n",
    "                        mask_backward(highmask,xstar,unet=UNET, mnet=mnet,\\\n",
    "                          beta=1.,alpha=alpha,c=c,\\\n",
    "                          maxIter=maxIter_mb,seed=0,break_limit=np.inf,\\\n",
    "                          lr=lr_mb,mode='UNET',budget=budget,normalize=False,\\\n",
    "                          dtyp=torch.float,verbose=True,testmode='sigpy',hfen=True,\\\n",
    "                          return_loss_only=True)\n",
    "        a_ind += 1\n",
    "    print('\\n')\n",
    "    c_ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6d5d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# highmask = sigmoid_binarize(raw_normalize(mnet(z),budget=budget))\n",
    "randmask = torch.zeros(highmask.shape)\n",
    "for ind in range(highmask.shape[0]):\n",
    "    sampinds = np.random.choice(highmask.shape[1],budget,replace=False)\n",
    "    randmask[ind,sampinds] = 1\n",
    "lowfmask,_,_ = mask_naiveRand(xstar.shape[1]-corefreq,fix=budget,other=0,roll=True)\n",
    "lowfmask = lowfmask.repeat(highmask.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff07b888",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# full_highmask = mask_complete(highmask,320)\n",
    "full_randmask = mask_complete(randmask,320)\n",
    "full_lowfmask = mask_complete(lowfmask,320)\n",
    "\n",
    "(rand_l2,rand_hfen) = mask_eval(full_randmask,xstar,mode='sigpy',hfen=True)\n",
    "(lowf_l2,lowf_hfen) = mask_eval(full_lowfmask,xstar,mode='sigpy',hfen=True)\n",
    "# (gred_l2,gred_hfen) = mask_eval(full_gredmask.to(torch.float),xstar,mode='sigpy',hfen=True)\n",
    "print('mode = sigpy')\n",
    "\n",
    "print(rand_l2)\n",
    "print(lowf_l2)\n",
    "# print(gred_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e858dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnet_loss = mask_eval(full_highmask,xstar,mode='UNET',UNET=UNET)\n",
    "# rand_loss = mask_eval(full_randmask,xstar,mode='UNET',UNET=UNET)\n",
    "# lowf_loss = mask_eval(full_lowfmask,xstar,mode='UNET',UNET=UNET)\n",
    "# print('mode = UNet')\n",
    "# mnet_loss = mask_eval(full_highmask,xstar,mode='sigpy')\n",
    "(rand_l2,rand_hfen) = mask_eval(full_randmask,xstar,mode='sigpy',hfen=True)\n",
    "(lowf_l2,lowf_hfen) = mask_eval(full_lowfmask,xstar,mode='sigpy',hfen=True)\n",
    "(gred_l2,gred_hfen) = mask_eval(full_gredmask.to(torch.float),xstar,mode='sigpy',hfen=True)\n",
    "print('mode = sigpy')\n",
    "# print(mnet_loss)\n",
    "\n",
    "print(rand_l2)\n",
    "print(lowf_l2)\n",
    "print(gred_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dc651a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(alpha_grid,l2loss)\n",
    "plt.plot(alpha_grid,np.ones(alpha_grid.shape)*rand_l2,label='rand')\n",
    "plt.plot(alpha_grid,np.ones(alpha_grid.shape)*lowf_l2,label='low freq.')\n",
    "plt.plot(alpha_grid,np.ones(alpha_grid.shape)*gred_l2,label='greedy')\n",
    "plt.title('l2 loss of masks')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(alpha_grid,hfen)\n",
    "plt.plot(alpha_grid,np.ones(alpha_grid.shape)*rand_hfen,label='rand')\n",
    "plt.plot(alpha_grid,np.ones(alpha_grid.shape)*lowf_hfen,label='low freq.')\n",
    "plt.plot(alpha_grid,np.ones(alpha_grid.shape)*gred_hfen,label='greedy')\n",
    "plt.title('HFEN of masks')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(alpha_grid,sparsity,label='actual')\n",
    "plt.plot(alpha_grid,(corefreq+budget)/320*np.ones(alpha_grid.shape),label='target')\n",
    "plt.title('mask sparsity')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ce6ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = ['H', 'D', 'P', 'X','+']\n",
    "plt.figure(figsize=(10,8))\n",
    "for c_ind in range(len(c_grid)):\n",
    "    plt.plot(alpha_grid,l2loss[:,c_ind],label='c='+str(c_grid[c_ind]),marker=markers[c_ind],markersize=7)\n",
    "plt.plot(alpha_grid,np.ones(alpha_grid.shape)*rand_l2,color='r',label='rand')\n",
    "plt.plot(alpha_grid,np.ones(alpha_grid.shape)*lowf_l2,color='g',label='low freq.')\n",
    "# plt.plot(alpha_grid,np.ones(alpha_grid.shape)*gred_l2,color='k',label='greedy')\n",
    "plt.title('l2 loss of masks')\n",
    "plt.xlabel('alpha')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "for c_ind in range(len(c_grid)):\n",
    "    plt.plot(alpha_grid,hfen[:,c_ind],label='c='+str(c_grid[c_ind]),marker=markers[c_ind],markersize=7)\n",
    "plt.plot(alpha_grid,np.ones(alpha_grid.shape)*rand_hfen,color='r',label='rand')\n",
    "plt.plot(alpha_grid,np.ones(alpha_grid.shape)*lowf_hfen,color='g',label='low freq.')\n",
    "# plt.plot(alpha_grid,np.ones(alpha_grid.shape)*gred_hfen,color='k',label='greedy')\n",
    "plt.title('HFEN of masks')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "for c_ind in range(len(c_grid)):\n",
    "    plt.plot(alpha_grid,sparsity[:,c_ind],label='c='+str(c_grid[c_ind]),marker=markers[c_ind],markersize=7)\n",
    "plt.plot(alpha_grid,(corefreq+budget)/320*np.ones(alpha_grid.shape),'-.',label='target')\n",
    "plt.title('mask sparsity')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('alpha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bfee72",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log10(alpha_grid[-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3217eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sigpy.mri.app import TotalVariationRecon\n",
    "xstar = imgs[0,:,:]/torch.max(torch.abs(imgs[0,:,:].flatten()))\n",
    "imgHeg, imgWid = xstar.shape[0], xstar.shape[1]\n",
    "mps = np.ones((1,imgHeg,imgWid))\n",
    "imgind = 15\n",
    "\n",
    "NN = 15\n",
    "Lambda_grid = 10**(np.linspace(-4,-2.5,NN))\n",
    "errors = np.zeros((NN))\n",
    "\n",
    "y = torch.fft.fftshift(F.fftn(xstar,dim=(0,1),norm='ortho'),dim=(0,1))    \n",
    "z = torch.zeros(y.shape).to(y.dtype)\n",
    "z[masks[imgind,:]==1,:] = y[masks[imgind,:]==1,:]  \n",
    "y_tmp = z.view(-1,imgHeg,imgWid).numpy()\n",
    "\n",
    "xstar = xstar.numpy()\n",
    "\n",
    "ind = 0\n",
    "for Lambda in Lambda_grid:    \n",
    "    x_tmp = np.fft.ifftshift( np.abs(TotalVariationRecon(y_tmp, mps, Lambda, show_pbar=False).run()) )  \n",
    "    errors[ind] = np.linalg.norm(x_tmp - xstar,'fro')/np.linalg.norm(xstar,'fro')\n",
    "    ind += 1\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(Lambda_grid,errors)\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93085e1",
   "metadata": {},
   "source": [
    "### tune weight initialization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aeeaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnet_weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    print(m)\n",
    "    if classname.find('Conv2d') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bb1004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload(utils)\n",
    "# from utils import mnet_weights_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33b6629",
   "metadata": {},
   "outputs": [],
   "source": [
    "corefreq = 8\n",
    "budget = 32\n",
    "\n",
    "mnet = MNet(beta=1,in_channels=2,out_size=320-corefreq, imgsize=(320,320),poolk=3)\n",
    "# mnet.apply(mnet_weights_init)\n",
    "# mnet.eval()\n",
    "mnet(torch.randn(1,2,320,320))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7e5f14",
   "metadata": {},
   "source": [
    "### old tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786959a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mask_backward_v3 import ThresholdBinarizeMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5649bf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "binarize = ThresholdBinarizeMask.apply\n",
    "x = torch.tensor([0.5,-0.5],requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbad87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = binarize(torch.sigmoid(3*x))\n",
    "ystar = torch.tensor([0.,1.])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b446840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 1/2*torch.norm(y - ystar,p=2)\n",
    "optimizer = optim.SGD([{'params': x}], lr=1e-2, momentum=0)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b7791a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e629a99",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_gt = np.load('/home/huangz78/data/data_gt.npz')\n",
    "picind = np.random.randint(199)\n",
    "xstar = data_gt['imgdata'][:,:,27]\n",
    "xstar = xstar/np.max(np.abs(xstar))\n",
    "# highmask = datafornn['labels'][picind,:]\n",
    "plt.figure()\n",
    "plt.imshow(xstar)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d810b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload(maskbackward)\n",
    "# from maskbackward import mask_backward\n",
    "\n",
    "#mode UNET:\n",
    "\n",
    "reload(mask_backward_new)\n",
    "from mask_backward_new import mask_backward,mask_eval\n",
    "\n",
    "dtyp = torch.float\n",
    "# unroll_block = 8; Lambda=6.1e-4; rho=1e1\n",
    "\n",
    "# base = .05; expand = .15\n",
    "# highmask = torch.zeros((round(320*(1-base))),dtype=torch.double)\n",
    "# highmask[np.random.choice(round(320*(1-base)),round(320*expand),replace=False)] = 1\n",
    "\n",
    "highmask = mask_filter(fullmask,base=round(320*0.05),roll=True)\n",
    "print(highmask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c977955",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = 1\n",
    "UNET =  UNet(n_channels=n_channels,n_classes=n_channels,bilinear=True,skip=False)\n",
    "checkpoint = torch.load('/home/huangz78/checkpoints/unet_' + str(n_channels) + '.pth')\n",
    "UNET.load_state_dict(checkpoint['model_state_dict'])\n",
    "UNET.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4667dba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## quick comparison between ifft recon and unet recon\n",
    "imgHeg = 320; imgWid = 320\n",
    "fullmask = torch.tensor( mask_complete(highmask,imgHeg,dtyp=torch.float) )\n",
    "kplot(fullmask)\n",
    "print('sparsity of fullmask = ',fullmask.sum().item()/imgHeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abde1d0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xstar = torch.tensor(xstar,dtype=dtyp)\n",
    "DTyp = torch.cfloat if dtyp==torch.float else torch.cdouble\n",
    "y = torch.fft.fftshift(F.fftn(xstar,dim=(0,1),norm='ortho'))\n",
    "z = torch.fft.ifftshift(torch.tensordot(torch.diag(fullmask).to(DTyp),y,dims=([1],[0])))\n",
    "kplot(y,roll=False,log=True)\n",
    "kplot(z,roll=True,log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8f465c",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgHeg = 320; imgWid = 320\n",
    "x_ifft = torch.abs(F.ifftn(z,dim=(0,1),norm='ortho')).to(dtyp)\n",
    "x_unet = UNET(x_ifft.view(1,1,imgHeg,imgWid)).detach()\n",
    "\n",
    "print('error of x_ifft = ', torch.norm(torch.flatten(x_ifft)-torch.flatten(xstar),'fro')/torch.norm(xstar,'fro') )\n",
    "print('error of x_unet = ', torch.norm(torch.flatten(x_unet)-torch.flatten(xstar),'fro')/torch.norm(xstar,'fro') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de0edd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sigpy.mri.app import TotalVariationRecon\n",
    "NN = 50\n",
    "Lambda_grid = 10**np.linspace(-3.5,-3,NN)\n",
    "errRec = np.zeros((NN))\n",
    "ind = 1\n",
    "\n",
    "mps  = np.ones((1,imgHeg,imgWid))\n",
    "y_sp = np.reshape(z.numpy(),(-1,imgHeg,imgWid))\n",
    "for Lambda in Lambda_grid:\n",
    "# Lambda = 10**(-6.31) \n",
    "# Lambda = 10**(-3.2755) # np.log10(Lambda_grid[np.argmin(errRec)])\n",
    "    print('{} out of {}'.format(ind,NN))\n",
    "    x_sp = np.fft.fftshift( np.abs(TotalVariationRecon(y_sp, mps, Lambda,show_pbar=False).run()) ) \n",
    "    x_sp = torch.tensor(x_sp)\n",
    "    errRec[ind-1] = torch.norm(torch.flatten(x_sp)-torch.flatten(xstar),'fro')/torch.norm(xstar,'fro')\n",
    "    ind += 1\n",
    "#     print('error of x_sp = ', torch.norm(torch.flatten(x_sp)-torch.flatten(xstar),'fro')/torch.norm(xstar,'fro'))\n",
    "\n",
    "plt.figure()\n",
    "plt.xscale('log')\n",
    "plt.plot(Lambda_grid,errRec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec30fdf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.linspace(-6,-4,gridnum)[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996e3afa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reload(mask_backward_new)\n",
    "from mask_backward_new import mask_backward,mask_eval\n",
    "\n",
    "maxIter = 200\n",
    "gridnum = 10\n",
    "alpha_grid = 10**np.linspace(-4.6,-4.5,gridnum)\n",
    "sr_rec = np.zeros((gridnum))\n",
    "mloss_rec = np.zeros(gridnum)\n",
    "\n",
    "ind = 0\n",
    "for alpha in alpha_grid:\n",
    "    print('[{}/{}]  alpha {}'.format(ind+1,gridnum,alpha))\n",
    "    highmask_refined,refine_mloss,init_loss = mask_backward(highmask,xstar,\\\n",
    "                          beta=1., alpha=alpha,maxIter=maxIter,seed=0,break_limit=maxIter//2,\\\n",
    "                          lr=5e-4,mode='UNET',\\\n",
    "                          verbose=False,dtyp=dtyp)\n",
    "    print('Difference between masks: \\n',highmask_refined - highmask)\n",
    "#     print('Refined mask is: \\n',highmask_refined)\n",
    "    mloss_rec[ind] = refine_mloss\n",
    "    sr_rec[ind] = (torch.sum(highmask_refined).item() + 24)/320\n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aad9bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(alpha_grid,mloss_rec,label='refined')\n",
    "plt.scatter(alpha_grid,init_loss*np.ones(mloss_rec.shape),label='init.')\n",
    "plt.title('mask loss')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(alpha_grid,sr_rec,label='refined')\n",
    "plt.scatter(alpha_grid,0.25*np.ones(mloss_rec.shape),label='init.')\n",
    "plt.title('mask sampling ratio')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5965033e",
   "metadata": {},
   "source": [
    "### mask binarize test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1b2e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Function\n",
    "class ThresholdBinarizeMask(Function):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "            Straight through estimator.\n",
    "            The forward step binarizes the real-valued mask.\n",
    "            The backward step estimate the non differentiable > operator using sigmoid with large slope (10).\n",
    "        \"\"\"\n",
    "        super(ThresholdBinarizeMask, self).__init__()\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        batch_size = len(input)\n",
    "        results = [] \n",
    "\n",
    "        for i in range(batch_size):\n",
    "            x = input[i:i+1]\n",
    "            result = (x > .5).float()\n",
    "            results.append(result)\n",
    "\n",
    "        results = torch.cat(results, dim=0)\n",
    "#         ctx.save_for_backward(input)\n",
    "        return results  \n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        slope = 1\n",
    "#         input = ctx.saved_tensors\n",
    "\n",
    "        # derivative of M\n",
    "        current_grad = slope\n",
    "\n",
    "        return current_grad * grad_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f544ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = ThresholdBinarizeMask.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbc3f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([.1,.3,.7,.9,.6,.5,.21,.43])\n",
    "x.requires_grad = True\n",
    "b = threshold(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1290d1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor([1., 1., 1., 1., 0., 1., 0., 1.])\n",
    "loss = torch.norm((y-b),p=2)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628d0b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD([{'params': x}], lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc84b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "print('old x: ', x)\n",
    "print('grad: ', x.grad)\n",
    "optimizer.step()\n",
    "print('updated x: ', x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de924ac1",
   "metadata": {},
   "source": [
    "### arXiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9528417",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(mask_backward_new)\n",
    "from mask_backward_new import mask_backward\n",
    "\n",
    "# mode ADMM:\n",
    "\n",
    "highmask = torch.zeros((round(320*0.9)))\n",
    "highmask[np.random.choice(round(320*0.9),int(320*.1),replace=False)] = 1\n",
    "\n",
    "naive_mloss = mask_eval(mask_complete(highmask.to(torch.double),320),xstar,unroll_block=unroll_block,Lambda=Lambda,rho=rho) * 100\n",
    "highmask_refined,refine_mloss = mask_backward(highmask,xstar,\\\n",
    "                          beta=1., alpha=1e1,maxIter=200,unroll_block=unroll_block,seed=0,break_limit=100,\\\n",
    "                          lr=5e-4,mode='ADMM',Lambda=Lambda,rho=rho,\\\n",
    "                          verbose=True,perturb=False,perturb_freq=5,eps=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e20ba17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vary sampling ratio, observe RMSE for the same image.\n",
    "reload(mask_backward_new)\n",
    "from mask_backward_new import mask_backward\n",
    "\n",
    "base=0.1\n",
    "r_grid = np.array([0.1,0.15,0.2])\n",
    "naive_mloss = np.zeros((r_grid.size))\n",
    "refine_mloss = np.zeros((r_grid.size))\n",
    "\n",
    "sampRatio = np.zeros((r_grid.size))\n",
    "\n",
    "unroll_block = 6; Lambda=6.1e-4; rho=1e1; lr = 5e-2\n",
    "maxIter = 300; break_limit = round(maxIter/3)\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "ind = 0\n",
    "for r in r_grid:\n",
    "    print('\\n r {}, the {} item out of {}'.format(r,ind+1,r_grid.size))\n",
    "    highmask = torch.zeros((round(320*(1-base))))\n",
    "    highmask[np.random.choice(round(320*(1-base)),int(320*r),replace=False)] = 1\n",
    "    \n",
    "    naive_mloss[ind] = mask_eval(mask_complete(highmask.to(torch.double),320),xstar,unroll_block=unroll_block,Lambda=Lambda,rho=rho) * 100\n",
    "    highmask_refined,refine_mloss[ind] = mask_backward(highmask,xstar,seed=0,\\\n",
    "                              beta=1., alpha=9.5e0,maxIter=maxIter,unroll_block=unroll_block,break_limit=break_limit,\\\n",
    "                              lr=lr,mode='ADMM',Lambda=Lambda,rho=rho,\\\n",
    "                              verbose=True,perturb=False,perturb_freq=5,eps=1e-2)\n",
    "    sampRatio[ind] = (highmask_refined.sum().item() + round(320*0.1))/320\n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a11c551",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('sampRatio: ',sampRatio)\n",
    "plt.figure()\n",
    "plt.scatter(r_grid,naive_mloss,label='naive')\n",
    "plt.scatter(sampRatio,refine_mloss,label='refined')\n",
    "plt.legend(bbox_to_anchor=(1.04,0.5), loc=\"center left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51682d9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## find a good alpha for l1 penalty\n",
    "reload(mask_backward_new); reload(utils);\n",
    "from mask_backward_new import mask_backward\n",
    "alpha_grid = np.linspace(1,10,10)\n",
    "sparsity_ = np.zeros(alpha_grid.size)\n",
    "change_count = np.zeros(alpha_grid.size)\n",
    "\n",
    "unroll_block = 6; Lambda=6.1e-4; rho=1e1; lr = 5e-2\n",
    "maxIter = 300; break_limit = round(maxIter/2)\n",
    "# add samp. ratio. = .1 ---> best alpha = ?\n",
    "# add samp. ratio. = .2 ---> best alpha = ?\n",
    "# add samp. ratio. = .2 ---> best alpha = ?\n",
    "\n",
    "base = 0.05\n",
    "additional = 0.125\n",
    "\n",
    "highmask = torch.zeros((round(320*(1-base))))\n",
    "highmask[np.random.choice(round(320*(1-base)),round(320*additional),replace=False)] = 1\n",
    "\n",
    "ind = 0\n",
    "for alpha in alpha_grid:\n",
    "    print('\\n\\talpha = {}'.format(alpha))\n",
    "    highmask_refined,_ = mask_backward(highmask,xstar,\\\n",
    "                  beta=1, alpha=alpha,maxIter=maxIter,unroll_block=unroll_block,seed=0,break_limit=break_limit,\\\n",
    "                  lr=lr,mode='ADMM',Lambda=Lambda,rho=rho,\\\n",
    "                  perturb=False,perturb_freq=10,verbose=True)\n",
    "    sparsity_[ind] = mask_complete(highmask_refined.to(torch.double),320).sum().item()/320\n",
    "    change_count[ind] = torch.abs(highmask_refined - highmask).sum().item()\n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db130dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(alpha_grid,sparsity_,label='end')\n",
    "plt.scatter(alpha_grid,(base+additional)*np.ones(alpha_grid.size),label='start')\n",
    "plt.title('sparsity')\n",
    "# plt.xscale('log')\n",
    "plt.legend(bbox_to_anchor=(1.04,0.5), loc=\"center left\")\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(alpha_grid,change_count)\n",
    "# plt.xscale('log')\n",
    "plt.title('change count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e701ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_mloss = mask_eval(mask_complete(highmask,imgHeg,dtyp=dtyp),xstar,mode='UNET',UNET=UNET,dtyp=dtyp) * 100\n",
    "print('naive mask loss = ',naive_mloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaeed03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### verify that UNET works fine\n",
    "z = apply_mask(full_gredmask,yfull,mode='c')\n",
    "xs = torch.abs(F.ifftn(F.ifftshift(z),dim=(1,2),norm='ortho'))\n",
    "xs = torch.reshape(xs,(xs.shape[0],1,xs.shape[1],xs.shape[2]))\n",
    "\n",
    "UNET.eval()\n",
    "imgind = 0\n",
    "xrecon = UNET(xs)\n",
    "plt.figure()\n",
    "plt.title('recon')\n",
    "plt.imshow(xrecon.detach().numpy()[imgind,0,:,:])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title('gt')\n",
    "plt.imshow(xstar.detach().numpy()[imgind,:,:])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "print(torch.norm(xrecon[imgind,0,:,:]-xstar[imgind,:,:],'fro')/torch.norm(xstar[imgind,:,:],'fro').item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460c2230",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(utils)\n",
    "from utils import hfen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a07d2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.squeeze(xrecon)[0,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4d0ec0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hfen(torch.squeeze(xrecon)[imgind,:,:],xstar[imgind,:,:],base=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
