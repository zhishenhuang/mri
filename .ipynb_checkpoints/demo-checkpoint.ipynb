{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48976408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.fft as F\n",
    "from importlib import reload\n",
    "from torch.nn.functional import relu\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Func\n",
    "import torch.optim as optim\n",
    "import utils\n",
    "from utils import *\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import skimage\n",
    "from mnet import MNet\n",
    "from loupe_env.loupe_wrap import *\n",
    "from mask_backward_v4 import *\n",
    "from sigpy.mri.app import TotalVariationRecon\n",
    "\n",
    "sys.path.insert(0,'/home/huangz78/mri/unet/')\n",
    "from unet_model import UNet\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8f08f4",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "963a8276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data shape:  torch.Size([1300, 320, 320])\n"
     ]
    }
   ],
   "source": [
    "testdata = torch.tensor(np.load('/mnt/shared_a/data/fastMRI/knee_singlecoil_test.npz')['data'])\n",
    "print('test data shape: ',testdata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c41b93cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNet loaded successfully from: /home/huangz78/checkpoints/mnet_split_trained_cf8_bg_32.pt\n",
      "Unet loaded successfully from: /home/huangz78/checkpoints/unet_split_trained_cf8_bg_32.pt\n",
      "nn's are ready\n",
      "sampling budget =  32\n"
     ]
    }
   ],
   "source": [
    "# load mnet\n",
    "sparsity = .125\n",
    "preselect_num = 8\n",
    "budget = int(testdata.shape[1]*sparsity - preselect_num)\n",
    "unet_skip = True\n",
    "mnet = MNet(beta=1,in_channels=2,out_size=320-preselect_num, imgsize=(320,320),poolk=3)\n",
    "# mnetpath = '/home/huangz78/checkpoints/mnet_split_trained_cf10_bg_43.pt'\n",
    "# mnetpath = '/home/huangz78/checkpoints/mnet_split_trained_cf16_bg_64.pt'\n",
    "mnetpath = '/home/huangz78/checkpoints/mnet_split_trained_cf8_bg_32.pt'\n",
    "checkpoint = torch.load(mnetpath)\n",
    "mnet.load_state_dict(checkpoint['model_state_dict'])\n",
    "# mnet.apply(mnet_weights_init)\n",
    "mnet.eval()\n",
    "print('MNet loaded successfully from: ' + mnetpath)\n",
    "\n",
    "unet_recon = UNet(n_channels=1,n_classes=1,bilinear=(not unet_skip),skip=unet_skip)\n",
    "unetpath = '/home/huangz78/checkpoints/unet_split_trained_cf8_bg_32.pt'\n",
    "# unetpath = '/home/huangz78/checkpoints/unet_split_trained_cf16_bg_64.pt'\n",
    "# unetpath = '/home/huangz78/checkpoints/unet_split_trained_cf10_bg_43.pt'\n",
    "checkpoint = torch.load(unetpath)\n",
    "unet_recon.load_state_dict(checkpoint['model_state_dict'])\n",
    "print('Unet loaded successfully from: ' + unetpath )\n",
    "unet_recon.eval()\n",
    "print('nn\\'s are ready')\n",
    "print('sampling budget = ', budget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b14a558e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and eval\n",
    "def mnet_eval(testdata,mnet,unet,budget,batchsize=25,device='cpu'):\n",
    "    for ind in range(testdata.shape[0]):\n",
    "        testdata[ind,:,:] = testdata[ind,:,:]/torch.max(testdata[ind,:,:])\n",
    "    print('test data size:', testdata.shape)\n",
    "    batch_nums  = int(np.ceil(testdata.shape[0]/batchsize))\n",
    "    lowfreqmask = mask_naiveRand(testdata.shape[1],fix=testdata.shape[1]-budget,other=0,roll=True)[0].to(device)\n",
    "    binarize = ThresholdBinarizeMask().apply\n",
    "    \n",
    "    l1err = torch.zeros(testdata.shape[0])\n",
    "    l2err = torch.zeros(testdata.shape[0])\n",
    "    hfens = torch.zeros(testdata.shape[0])\n",
    "    ssims = torch.zeros(testdata.shape[0])\n",
    "    psnrs = torch.zeros(testdata.shape[0])\n",
    "    \n",
    "    batchind = 0\n",
    "    while batchind<batch_nums:\n",
    "        batch = torch.arange(batchsize*batchind, min(batchsize*(batchind+1),testdata.shape[0]))\n",
    "        xstar = testdata[batch,:,:].to(torch.float).to(device)\n",
    "        yfull = torch.fft.fftshift(F.fftn(xstar,dim=(1,2),norm='ortho'),dim=(1,2)) # y is ROLLED!\n",
    "        \n",
    "        y = torch.zeros((yfull.shape[0],2,yfull.shape[1],yfull.shape[2]),dtype=torch.float,device=device)\n",
    "        y[:,0,lowfreqmask==1,:] = torch.real(yfull)[:,lowfreqmask==1,:]\n",
    "        y[:,1,lowfreqmask==1,:] = torch.imag(yfull)[:,lowfreqmask==1,:]\n",
    "        mask_test = mnet_wrapper(mnet,y,budget,(testdata.shape[1],testdata.shape[2]),\\\n",
    "                                 normalize=True,detach=True,device=device)\n",
    "        \n",
    "        z = torch.zeros(xstar.shape,device=device).to(torch.cfloat)\n",
    "        for ind in range(len(xstar)):\n",
    "            z[ind,mask_test[ind,:]==1,:] = y[ind,0,mask_test[ind,:]==1,:] + 1j*y[ind,1,mask_test[ind,:]==1,:]\n",
    "        z = torch.fft.ifftshift(z , dim=(1,2)) \n",
    "        \n",
    "        x_ifft = torch.abs( F.ifftn(z,dim=(1,2),norm='ortho') )\n",
    "        x_in   = x_ifft.view(len(xstar),1,testdata.shape[1],testdata.shape[2])\n",
    "        x      = torch.squeeze(unet(x_in).detach())\n",
    "           \n",
    "        # to implement various criteria\n",
    "        l1err[batch] = compute_l1err(x,xstar)\n",
    "        l2err[batch] = compute_l2err(x,xstar)\n",
    "        hfens[batch] = torch.tensor(compute_hfen(x,xstar))\n",
    "        ssims[batch] = torch.tensor(compute_ssim(x,xstar))\n",
    "        psnrs[batch] = torch.tensor(compute_psnr(x,xstar))\n",
    "        \n",
    "        batchind += 1\n",
    "    return l1err,l2err,hfens,ssims,psnrs\n",
    "\n",
    "# print eval result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bca5fa70",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data size: torch.Size([1300, 320, 320])\n"
     ]
    }
   ],
   "source": [
    "l1err,l2err,hfens,ssims,psnrs = mnet_eval(testdata,mnet,unet_recon,budget,batchsize=15,device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a47a856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(ssims.numpy())\n",
    "# plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1331b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1err.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a99a807",
   "metadata": {},
   "source": [
    "# comparison between MNet and Loupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c6abe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtyp = torch.float\n",
    "testxdata  = np.load('/home/huangz78/data/testdata_x.npz')\n",
    "testydata  = np.load('/home/huangz78/data/testdata_y.npz')\n",
    "testxfull = torch.tensor(testxdata['xfull'],dtype=dtyp)\n",
    "testyfull = torch.tensor(testydata['yfull'],dtype=torch.cfloat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f0ba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparsity = .25\n",
    "# preselect_num = 24\n",
    "# unet_skip = True\n",
    "\n",
    "sparsity = .125\n",
    "preselect_num = 8\n",
    "unet_skip = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4280a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mnet\n",
    "mnet = MNet(beta=1,in_channels=2,out_size=320-preselect_num, imgsize=(320,320),poolk=3)\n",
    "# mnetpath = '/home/huangz78/checkpoints/mnet.pth'\n",
    "mnetpath = '/home/huangz78/checkpoints/mnet_split_trained_cf8_bg_32.pt'\n",
    "checkpoint = torch.load(mnetpath)\n",
    "mnet.load_state_dict(checkpoint['model_state_dict'])\n",
    "mnet.eval()\n",
    "print('MNet loaded successfully from: ' + mnetpath)\n",
    "\n",
    "unet_recon = UNet(n_channels=1,n_classes=1,bilinear=(not unet_skip),skip=unet_skip)\n",
    "unetpath = '/home/huangz78/checkpoints/unet_1_True.pth'\n",
    "checkpoint = torch.load(unetpath)\n",
    "unet_recon.load_state_dict(checkpoint['model_state_dict'])\n",
    "print('Unet loaded successfully from: ' + unetpath )\n",
    "unet_recon.eval()\n",
    "print('nn\\'s are ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf7efb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnet_eval(mnet,unet,testdata,preselect_num,sparsity,\\\n",
    "             batchsize=5,mode='unet',\\\n",
    "             Lambda=1e-4,\\\n",
    "             normalize=False):\n",
    "    \n",
    "    # prepare test data for mnet input\n",
    "    nimgs = testdata.shape[0]; heg = testdata.shape[1]; wid = testdata.shape[2]\n",
    "    \n",
    "    data = torch.zeros(nimgs,2,heg,wid)    \n",
    "    lf_mask = mask_naiveRand(heg,fix=preselect_num,other=0,roll=False)\n",
    "    data[:,0,lf_mask==1,:] = torch.real(testdata[:,lf_mask==1,:])\n",
    "    data[:,1,lf_mask==1,:] = torch.imag(testdata[:,lf_mask==1,:])\n",
    "    \n",
    "    pred_mnet = torch.zeros((nimgs,heg))\n",
    "    batchnums = int(np.ceil(nimgs/batchsize))\n",
    "    batchind = 0\n",
    "    while batchind < batchnums:\n",
    "        batch = np.arange(batchsize*batchind, min(batchsize*(batchind+1),nimgs))\n",
    "        databatch = data[batch]\n",
    "        preds = mnet_wrapper(mnet,databatch,budget=int(heg*sparsity)-preselect_num,\\\n",
    "                             imgshape=[heg,wid],normalize=True,detach=True)\n",
    "        pred_mnet[batch] = F.ifftshift(preds,dim=1)\n",
    "        batchind += 1\n",
    "    \n",
    "    observed_kspace = torch.zeros_like(testdata)\n",
    "    for ind in range(len(data)):\n",
    "        observed_kspace[ind,pred_mnet[ind,:]==1,:] = testdata[ind,pred_mnet[ind,:]==1,:]\n",
    "    imgs_recon = torch.zeros(testdata.shape)\n",
    "    \n",
    "    if mode == 'unet':\n",
    "        input_unet = F.ifftn(observed_kspace,dim=(1,2),norm='ortho').abs().view(nimgs,1,heg,wid)\n",
    "        batchind = 0\n",
    "        while batchind < batchnums:\n",
    "            batch = np.arange(batchsize*batchind, min(batchsize*(batchind+1),nimgs))\n",
    "            databatch = input_unet[batch]\n",
    "            if not normalize:\n",
    "                imgs_recon[batch] = torch.squeeze(unet(databatch).detach())\n",
    "            else:\n",
    "                recon_batch = unet(databatch).detach()\n",
    "                for ind in range(len(recon_batch)):\n",
    "                    recon_batch[ind] = recon_batch[ind]/torch.max(torch.abs(torch.flatten(recon_batch[ind])))\n",
    "                imgs_recon[batch] = torch.squeeze(recon_batch)\n",
    "            batchind += 1\n",
    "    elif mode == 'sigpy':\n",
    "        mps = np.ones((1,heg,wid))\n",
    "        for ind in range(len(observed_kspace)):\n",
    "            y_tmp = observed_kspace[ind,:,:].view(-1,heg,wid).numpy()\n",
    "            imgs_recon[ind,:,:] = torch.tensor(\\\n",
    "                       np.fft.ifftshift(np.abs(TotalVariationRecon(y_tmp, mps, Lambda,show_pbar=False).run())) )\n",
    "\n",
    "    ssim = compute_ssim(imgs_recon,testdata)\n",
    "    psnr = compute_psnr(imgs_recon,testdata)\n",
    "    hfen = np.zeros((nimgs))\n",
    "    for ind in range(nimgs):\n",
    "        hfen[ind] = compute_hfen(imgs_recon[ind,:,:].to(torch.cfloat),testdata[ind,:,:].to(torch.cfloat))\n",
    "    rmse = np.zeros((nimgs))\n",
    "    for ind in range(nimgs):\n",
    "        rmse[ind] = torch.norm(imgs_recon[ind,:,:] - testdata[ind,:,:],2)/torch.norm(testdata[ind,:,:],2)\n",
    "    \n",
    "    return ssim,psnr,hfen,rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a6e7c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mnet_test_mode = 'sigpy'\n",
    "ssim_mnet,psnr_mnet,hfen_mnet,rmse_mnet = mnet_eval(mnet,unet_recon,testyfull,preselect_num=24,sparsity=.25,\\\n",
    "                               batchsize=5,mode=mnet_test_mode,normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb8891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mnet test mode: ',mnet_test_mode)\n",
    "print('ssim mnet: ',np.mean(ssim_mnet))\n",
    "print('psnr mnet: ',np.mean(psnr_mnet))\n",
    "print('hfen mnet: ',np.mean(hfen_mnet))\n",
    "print('rmse mnet: ',np.mean(rmse_mnet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c22976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load unet\n",
    "unet_skip = False\n",
    "UNET = UNet(n_channels=1,n_classes=1,bilinear=(not unet_skip),skip=unet_skip)\n",
    "# load loupe model\n",
    "loupepath = '/home/huangz78/checkpoints/loupe_skipTrue.pt'\n",
    "loupe = LOUPE(n_channels=1,unet_skip=True,shape=[320,320],slope=5,sparsity=sparsity,\\\n",
    "                  preselect=True,preselect_num=preselect_num,\\\n",
    "                  sampler=None,unet=UNET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9603e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loupe_eval(loupe,testdata,preselect_num,sparsity,\\\n",
    "               batchsize=5,mode='unet',\\\n",
    "               Lambda=1e-4):\n",
    "    loupe.eval()\n",
    "    if preselect_num > 0:\n",
    "        assert loupe.preselect\n",
    "        assert loupe.preselect_num == preselect_num\n",
    "    # prepare test data for mnet input\n",
    "    nimgs = testdata.shape[0]; heg = testdata.shape[1]; wid = testdata.shape[2]    \n",
    "    data = torch.reshape(testdata,(nimgs,1,heg,wid))\n",
    "    \n",
    "    pred_loupe = torch.zeros((nimgs,heg,wid)) \n",
    "    batchnums = int(np.ceil(nimgs/batchsize))\n",
    "    batchind = 0    \n",
    "    if mode == 'unet':           \n",
    "        while batchind < batchnums:\n",
    "            batch = np.arange(batchsize*batchind, min(batchsize*(batchind+1),nimgs))\n",
    "            databatch = data[batch]\n",
    "            preds,_ = loupe(databatch)\n",
    "            pred_loupe[batch] = torch.squeeze( preds.detach() )\n",
    "            batchind += 1\n",
    "    elif mode == 'sigpy':\n",
    "        masks_loupe = torch.zeros((batchnums,heg))\n",
    "        while batchind < batchnums:\n",
    "            batch = np.arange(batchsize*batchind, min(batchsize*(batchind+1),nimgs))\n",
    "            databatch = data[batch]\n",
    "            _,mask = loupe.samplers[0](databatch,sparsity)\n",
    "\n",
    "            mask = torch.squeeze(mask.detach())\n",
    "            masks_loupe[batchind,:] = mask\n",
    "            observed_kspace = torch.zeros_like(databatch)\n",
    "            imgs_recon = torch.zeros((len(databatch),heg,wid))\n",
    "            observed_kspace[:,:,mask==1,:] = databatch[:,:,mask==1,:]\n",
    "            \n",
    "            mps = np.ones((1,heg,wid))\n",
    "            for ind in range(len(observed_kspace)):\n",
    "                y_tmp = observed_kspace[ind,0,:,:].view(-1,heg,wid).numpy()\n",
    "                imgs_recon[ind,:,:] = torch.tensor(\\\n",
    "                           np.fft.ifftshift(np.abs(TotalVariationRecon(y_tmp, mps, Lambda,show_pbar=False).run())) )\n",
    "            pred_loupe[batch] = imgs_recon\n",
    "            batchind += 1\n",
    "        \n",
    "    ssim = compute_ssim(pred_loupe,testdata)\n",
    "    psnr = compute_psnr(pred_loupe,testdata)\n",
    "    hfen = np.zeros((nimgs))\n",
    "    for ind in range(nimgs):\n",
    "        hfen[ind] = compute_hfen(pred_loupe[ind,:,:].to(torch.cfloat),testdata[ind,:,:].to(torch.cfloat))\n",
    "    rmse = np.zeros((nimgs))\n",
    "    for ind in range(nimgs):\n",
    "        rmse[ind] = torch.norm(pred_loupe[ind,:,:] - testdata[ind,:,:],2)/torch.norm(testdata[ind,:,:],2)\n",
    "    \n",
    "    return ssim,psnr,hfen,rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94945eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "loupe_test_mode = 'unet'\n",
    "ssim_loupe,psnr_loupe,hfen_loupe,rmse_loupe = loupe_eval(loupe,testyfull,preselect_num=24,sparsity=.25,\\\n",
    "                               batchsize=5,mode=loupe_test_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a7fbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mnet test mode: ',mnet_test_mode)\n",
    "print('ssim loupe: ',np.mean(ssim_loupe))\n",
    "print('psnr loupe: ',np.mean(psnr_loupe))\n",
    "print('hfen loupe: ',np.mean(hfen_loupe))\n",
    "print('rmse loupe: ',np.mean(rmse_loupe))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abc4a30",
   "metadata": {},
   "source": [
    "# main demo: show masks and triviality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2836531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "heg = 320\n",
    "wid = 320\n",
    "sparsity = 53/320 # .25 # .125\n",
    "preselect_num = 10 # 16 # 8\n",
    "budget = int(heg * sparsity - preselect_num)\n",
    "unet_skip = True\n",
    "print(f'budget is {budget}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2fe629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mnet\n",
    "mnet = MNet(beta=1,in_channels=2,out_size=320-preselect_num, imgsize=(320,320),poolk=3)\n",
    "mnetpath = '/home/huangz78/checkpoints/mnet_split_trained_cf10_bg_43.pt'\n",
    "# mnetpath = '/home/huangz78/checkpoints/mnet_split_trained_cf16_bg_64.pt'\n",
    "# mnetpath = '/home/huangz78/checkpoints/mnet_split_trained_cf8_bg_32.pt'\n",
    "checkpoint = torch.load(mnetpath)\n",
    "mnet.load_state_dict(checkpoint['model_state_dict'])\n",
    "# mnet.apply(mnet_weights_init)\n",
    "mnet.eval()\n",
    "print('MNet loaded successfully from: ' + mnetpath)\n",
    "\n",
    "unet_recon = UNet(n_channels=1,n_classes=1,bilinear=(not unet_skip),skip=unet_skip)\n",
    "# unetpath = '/home/huangz78/checkpoints/unet_split_trained_cf8_bg_32.pt'\n",
    "# unetpath = '/home/huangz78/checkpoints/unet_split_trained_cf16_bg_64.pt'\n",
    "unetpath = '/home/huangz78/checkpoints/unet_split_trained_cf10_bg_43.pt'\n",
    "checkpoint = torch.load(unetpath)\n",
    "unet_recon.load_state_dict(checkpoint['model_state_dict'])\n",
    "print('Unet loaded successfully from: ' + unetpath )\n",
    "unet_recon.eval()\n",
    "print('nn\\'s are ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c90c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgind = 126\n",
    "kimg = testyfull[imgind].view(1,1,heg,heg)\n",
    "\n",
    "_,loupe_mask = loupe.samplers[0](kimg,sparsity)\n",
    "loupe_mask = torch.squeeze(loupe_mask.detach())\n",
    "kplot(loupe_mask,roll=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09799d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "imgs = torch.tensor( np.load('/home/huangz78/data/data_gt.npz')['imgdata'] ).permute(2,0,1)\n",
    "labels = torch.tensor( np.load('/home/huangz78/data/data_gt_greedymask.npz')['mask'].T ) # labels are already rolled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9a0ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgind_1 = 12\n",
    "img_1 = imgs[imgind_1,:,:].view(1,1,heg,wid)/torch.max(torch.abs(imgs[imgind_1,:,:]))\n",
    "kimg_1 = F.fftshift(F.fftn(img_1,dim=(2,3),norm='ortho').to(torch.cfloat)) # kspace shifted\n",
    "lfmask,_,_ = mask_naiveRand(heg,fix=preselect_num,other=0,roll=True)\n",
    "rdmask,_,_ = mask_naiveRand(heg,fix=preselect_num,other=budget,roll=True)\n",
    "\n",
    "kimg_lf_1 = torch.zeros(1,2,heg,wid)    \n",
    "kimg_lf_1[:,0,lfmask==1,:] = torch.real(kimg_1[:,:,lfmask==1,:])\n",
    "kimg_lf_1[:,1,lfmask==1,:] = torch.imag(kimg_1[:,:,lfmask==1,:])\n",
    "# _,loupe_mask = loupe.samplers[0](kimg,sparsity)\n",
    "# loupe_mask = torch.squeeze(loupe_mask.detach())\n",
    "# kplot(loupe_mask,roll=True)\n",
    "\n",
    "mnet_mask_1 = mnet_wrapper(mnet,kimg_lf_1,budget=int(heg*sparsity)-preselect_num,\\\n",
    "                             imgshape=[heg,wid],normalize=True,detach=True)\n",
    "mnet_mask_1 = torch.squeeze(mnet_mask_1)\n",
    "\n",
    "greedy_mask_1 = labels[imgind_1,:]\n",
    "\n",
    "kplot(mnet_mask_1,roll=False,img_name='mnet mask 1')\n",
    "print('quality of mnet mask for image 1: ', mask_eval(mnet_mask_1.view(-1,320),img_1.view(1,heg,wid),\\\n",
    "              mode='UNET',UNET=unet_recon,dtyp=torch.float,\\\n",
    "              Lambda=10**(-4.3),hfen=False))\n",
    "\n",
    "kplot(greedy_mask_1,roll=False,img_name='greedy mask 1')\n",
    "print('quality of greedy mask for image 1: ',mask_eval(greedy_mask_1.view(-1,320),img_1.view(1,heg,wid),\\\n",
    "              mode='UNET',UNET=unet_recon,dtyp=torch.float,\\\n",
    "              Lambda=10**(-4.3),hfen=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd49f26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for imgind_2 in range(20):\n",
    "# imgind_2 = 693\n",
    "    print(imgind_2)\n",
    "    img_2 = imgs[imgind_2,:,:].view(1,1,heg,wid)/torch.max(torch.abs(imgs[imgind_2,:,:]))\n",
    "    kimg_2 = F.fftshift(F.fftn(img_2,dim=(2,3),norm='ortho').to(torch.cfloat)) # kspace shifted\n",
    "\n",
    "    kimg_lf_2 = torch.zeros(1,2,heg,wid)    \n",
    "    kimg_lf_2[:,0,lfmask==1,:] = torch.real(kimg_2[:,:,lfmask==1,:])\n",
    "    kimg_lf_2[:,1,lfmask==1,:] = torch.imag(kimg_2[:,:,lfmask==1,:])\n",
    "\n",
    "    mnet_mask_2 = mnet_wrapper(mnet,kimg_lf_2,budget=int(heg*sparsity)-preselect_num,\\\n",
    "                                 imgshape=[heg,wid],normalize=True,detach=True)\n",
    "    mnet_mask_2 = torch.squeeze(mnet_mask_2)\n",
    "\n",
    "    greedy_mask_2 = labels[imgind_2,:]\n",
    "\n",
    "    \n",
    "    # kplot(greedy_mask_2,roll=False,img_name='greedy mask 2')\n",
    "\n",
    "    slope = 1\n",
    "    if (mnet_mask_1 - mnet_mask_2).abs().sum() > 0:\n",
    "        kplot(mnet_mask_2,roll=False,img_name='mnet mask 2')\n",
    "        print('direct input difference: ',kimg_lf_1[:,:,lfmask==1,:] - kimg_lf_2[:,:,lfmask==1,:])\n",
    "        print('sigmoid mnet output difference: ',torch.sigmoid(slope * mnet(kimg_lf_1)) - torch.sigmoid(slope * mnet(kimg_lf_2)))\n",
    "        print('mask difference: ', mnet_mask_1 - mnet_mask_2) \n",
    "        print('mnet total line count difference: ', (mnet_mask_1 - mnet_mask_2).abs().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118c4677",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# image reconstruction\n",
    "kimg_mn_1 = torch.zeros(1,1,heg,wid).to(torch.cfloat)   \n",
    "kimg_mn_1[:,:,mnet_mask_1==1,:] = kimg_1[:,:,mnet_mask_1==1,:]\n",
    "xifft_mn_1 = torch.abs( F.ifftn(F.ifftshift(kimg_mn_1),dim=(2,3),norm='ortho') ) # kspace shifted\n",
    "\n",
    "kimg_rd_1 = torch.zeros(1,1,heg,wid).to(torch.cfloat)   \n",
    "kimg_rd_1[:,:,rdmask==1,:] = kimg_1[:,:,rdmask==1,:]\n",
    "xifft_rd_1 = torch.abs( F.ifftn(F.ifftshift(kimg_rd_1),dim=(2,3),norm='ortho') )\n",
    "\n",
    "kimg_gr_1 = torch.zeros(1,1,heg,wid).to(torch.cfloat)  \n",
    "kimg_gr_1[:,:,greedy_mask_1==1,:] = kimg_1[:,:,greedy_mask_1==1,:]\n",
    "xifft_gr_1 = torch.abs( F.ifftn(F.ifftshift(kimg_gr_1),dim=(2,3),norm='ortho') )\n",
    "\n",
    "mode = 'unet'\n",
    "# mode = 'sigpy'\n",
    "if mode == 'unet':\n",
    "    print(f'mode is {mode}')\n",
    "    xrecon_mn_1 = unet_recon(xifft_mn_1).detach()\n",
    "    xrecon_rd_1 = unet_recon(xifft_rd_1).detach()\n",
    "    xrecon_gr_1 = unet_recon(xifft_gr_1).detach()\n",
    "    kplot(xrecon_mn_1[0,0,:,:],img_name='mnet-masked recon by unet')\n",
    "    kplot(xrecon_rd_1[0,0,:,:],img_name='random-masked recon by unet')\n",
    "    kplot(xrecon_gr_1[0,0,:,:],img_name='greedy-masked recon by unet')\n",
    "    kplot(torch.abs(xrecon_mn_1[0,0,:,:] - img_1[0,0,:,:]),img_name='mnet-recon error')\n",
    "    kplot(torch.abs(xrecon_rd_1[0,0,:,:] - img_1[0,0,:,:]),img_name='random-recon error')\n",
    "    kplot(torch.abs(xrecon_gr_1[0,0,:,:] - img_1[0,0,:,:]),img_name='greedy-recon error')\n",
    "    print(f'mode is {mode}')\n",
    "    print('mnet   recon psnr: ',compute_psnr(xrecon_mn_1.view(-1,320,320), img_1.view(-1,320,320)))\n",
    "    print('random recon psnr: ',compute_psnr(xrecon_rd_1.view(-1,320,320), img_1.view(-1,320,320)))\n",
    "    print('greedy recon psnr: ',compute_psnr(xrecon_gr_1.view(-1,320,320), img_1.view(-1,320,320)))\n",
    "    print('\\n')\n",
    "    print('mnet   recon ssim: ',compute_ssim(xrecon_mn_1.view(-1,320,320), img_1.view(-1,320,320)))\n",
    "    print('random recon ssim: ',compute_ssim(xrecon_rd_1.view(-1,320,320), img_1.view(-1,320,320)))\n",
    "    print('greedy recon ssim: ',compute_ssim(xrecon_gr_1.view(-1,320,320), img_1.view(-1,320,320)))\n",
    "    print('\\n')\n",
    "    print('mnet   recon l2 err: ',(torch.norm(xrecon_mn_1-img_1)/torch.norm(img_1)).item())\n",
    "    print('random recon l2 err: ',(torch.norm(xrecon_rd_1-img_1)/torch.norm(img_1)).item())\n",
    "    print('greedy recon l2 err: ',(torch.norm(xrecon_gr_1-img_1)/torch.norm(img_1)).item())\n",
    "    print('\\n')\n",
    "    print('mnet   recon l1 err: ',(torch.norm(xrecon_mn_1-img_1,p=1)/torch.norm(img_1,p=1)).item())\n",
    "    print('random recon l1 err: ',(torch.norm(xrecon_rd_1-img_1,p=1)/torch.norm(img_1,p=1)).item())\n",
    "    print('greedy recon l1 err: ',(torch.norm(xrecon_gr_1-img_1,p=1)/torch.norm(img_1,p=1)).item())\n",
    "    \n",
    "elif mode == 'sigpy':\n",
    "    print(f'mode is {mode}')\n",
    "    mps = np.ones((1,320,320))\n",
    "    Lambda = 1e-4\n",
    "    kimg_mn_1 = kimg_mn_1.view(-1,320,320).numpy()\n",
    "    xrecon_mn_1 = np.fft.ifftshift( np.abs(TotalVariationRecon(kimg_mn_1, mps, Lambda,show_pbar=False).run()) )\n",
    "    \n",
    "    kimg_rd_1 = kimg_rd_1.view(-1,320,320).numpy()\n",
    "    xrecon_rd_1 = np.fft.ifftshift( np.abs(TotalVariationRecon(kimg_rd_1, mps, Lambda,show_pbar=False).run()) )\n",
    "    \n",
    "    kimg_gr_1 = kimg_gr_1.view(-1,320,320).numpy()\n",
    "    xrecon_gr_1 = np.fft.ifftshift( np.abs(TotalVariationRecon(kimg_gr_1, mps, Lambda,show_pbar=False).run()) )\n",
    "    \n",
    "    kplot(xrecon_mn_1,img_name='mnet-masked recon by sigpy')\n",
    "    kplot(xrecon_rd_1,img_name='random-masked recon by sigpy')\n",
    "    kplot(xrecon_gr_1,img_name='greedy-masked recon by sigpy')\n",
    "    kplot(np.abs(xrecon_mn_1 - img_1[0,0,:,:].numpy()),img_name='mnet-recon error')\n",
    "    kplot(np.abs(xrecon_rd_1 - img_1[0,0,:,:].numpy()),img_name='random-recon error')\n",
    "    kplot(np.abs(xrecon_gr_1 - img_1[0,0,:,:].numpy()),img_name='greedy-recon error')\n",
    "    print(f'mode is {mode}')\n",
    "    print('mnet   recon psnr: ',compute_psnr(torch.tensor(xrecon_mn_1).view(-1,320,320), img_1.view(-1,320,320)))\n",
    "    print('random recon psnr: ',compute_psnr(torch.tensor(xrecon_rd_1).view(-1,320,320), img_1.view(-1,320,320)))\n",
    "    print('greedy recon psnr: ',compute_psnr(torch.tensor(xrecon_gr_1).view(-1,320,320), img_1.view(-1,320,320)))\n",
    "    print('\\n')\n",
    "    print('mnet   recon ssim: ',compute_ssim(torch.tensor(xrecon_mn_1).view(-1,320,320), img_1.view(-1,320,320)))\n",
    "    print('random recon ssim: ',compute_ssim(torch.tensor(xrecon_rd_1).view(-1,320,320), img_1.view(-1,320,320)))\n",
    "    print('greedy recon ssim: ',compute_ssim(torch.tensor(xrecon_gr_1).view(-1,320,320), img_1.view(-1,320,320)))\n",
    "    print('\\n')\n",
    "    print('mnet   recon l2 err: ',(torch.norm(torch.tensor(xrecon_mn_1).view(img_1.shape)-img_1)/torch.norm(img_1)).item())\n",
    "    print('random recon l2 err: ',(torch.norm(torch.tensor(xrecon_rd_1).view(img_1.shape)-img_1)/torch.norm(img_1)).item())\n",
    "    print('greedy recon l2 err: ',(torch.norm(torch.tensor(xrecon_gr_1).view(img_1.shape)-img_1)/torch.norm(img_1)).item())\n",
    "    print('\\n')\n",
    "    print('mnet   recon l1 err: ',(torch.norm(torch.tensor(xrecon_mn_1).view(img_1.shape)-img_1,p=1)/torch.norm(img_1,p=1)).item())\n",
    "    print('random recon l1 err: ',(torch.norm(torch.tensor(xrecon_rd_1).view(img_1.shape)-img_1,p=1)/torch.norm(img_1,p=1)).item())\n",
    "    print('greedy recon l1 err: ',(torch.norm(torch.tensor(xrecon_gr_1).view(img_1.shape)-img_1,p=1)/torch.norm(img_1,p=1)).item())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b17c896",
   "metadata": {},
   "source": [
    "# mnet and loupe training error check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142bc2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = np.load('/home/huangz78/checkpoints/mnet_train_history.npz')\n",
    "print(rec.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59c591b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wid1 = 10\n",
    "wid2 = 5\n",
    "plt.figure()\n",
    "plt.plot(rolling_mean(rec['precision_train'],wid1),label='precision')\n",
    "plt.plot(rolling_mean(rec['recall_train'],wid1),label='recall')\n",
    "plt.title('training accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title('testing accuracy')\n",
    "plt.plot(rolling_mean(rec['precision_test'],wid2),label='precision')\n",
    "plt.plot(rolling_mean(rec['recall_test'],wid2),label='recall')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title('train loss in cross entropy')\n",
    "plt.plot(rolling_mean(rec['loss_train'],20),label='train')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title('test loss in cross entropy')\n",
    "plt.plot(rolling_mean(rec['loss'],8),color='orange',label='test')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388c8f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = np.load('/home/huangz78/checkpoints/loupe_history.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76917f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train = rec['loss_train']\n",
    "loss_val = rec['loss_val']\n",
    "plt.figure()\n",
    "plt.plot(loss_train)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.title('training loss')\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.plot(loss_val)\n",
    "plt.yscale('log')\n",
    "plt.title('validation loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc39bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = np.load('/home/huangz78/checkpoints/alternating_update_error_track_8fold.npz')\n",
    "print(rec.files)\n",
    "# loss_vals = list(rec['loss_val'])\n",
    "# loss_vals.append(0.10742834150791167)\n",
    "# print(loss_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd88f9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec['loss_rand'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3078f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_mean(x,window):\n",
    "    window = int(window)\n",
    "#   y = np.zeros(x.size-window)\n",
    "#   for ind in range(y.size):\n",
    "#       y[ind] = np.mean(x[ind:ind+window])\n",
    "\n",
    "    # Stephen: for large data, the above gets a bit slow, so we can do this:\n",
    "#   y = np.convolve(x, np.ones(window)/window, mode='valid')\n",
    "#   return y\n",
    "    # or https://stackoverflow.com/a/27681394\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0))\n",
    "    return (cumsum[window:] - cumsum[:-window]) / float(window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93f8eab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figsize=(10,6)\n",
    "window = 20\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "plt.plot(rolling_mean(rec['loss_rand'],window)   ,label='loss random')\n",
    "plt.plot(rolling_mean(rec['loss_before'],window) ,label='loss mnet_pred')\n",
    "plt.plot(rolling_mean(rec['loss_after'],window)  ,label='loss mask_backward')\n",
    "plt.title('training mask loss')\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "plt.plot(rolling_mean(rec['loss_before'] - rec['loss_rand'],window)   ,label='mnet_pred - random')\n",
    "plt.plot(rolling_mean(rec['loss_before'] - rec['loss_after'],window)  ,label='mnet_pred - mask_backward')\n",
    "zero_line = np.zeros((len(rec['loss_rand'])))\n",
    "plt.plot(zero_line,'--',label='zero threshold',color='r',linewidth=5)\n",
    "plt.title('training mask loss difference comparison')\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "plt.plot(rec['loss_val'])\n",
    "plt.title('validation loss')\n",
    "# plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9c97d2",
   "metadata": {},
   "source": [
    "# mnet quality check: y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c474fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = MNet(beta=1,in_channels=2,out_size=320-24,\\\n",
    "                   imgsize=(320,320),poolk=3)\n",
    "checkpoint = torch.load('/home/huangz78/checkpoints/mnet.pth')\n",
    "net.load_state_dict(checkpoint['model_state_dict'])\n",
    "print('MNet loaded successfully from: ' + '/home/huangz78/checkpoints/mnet.pth')\n",
    "net.eval()\n",
    "\n",
    "imgs = torch.tensor( np.load('/home/huangz78/data/data_gt.npz')['imgdata'] ).permute(2,0,1)\n",
    "base = 24\n",
    "mask_lf,_,_ = mask_naiveRand(imgs.shape[1],fix=base,other=0,roll=True)\n",
    "\n",
    "yfulls = torch.zeros((imgs.shape[0],2,imgs.shape[1],imgs.shape[2]),dtype=torch.float)\n",
    "ys     = torch.zeros((imgs.shape[0],2,imgs.shape[1],imgs.shape[2]),dtype=torch.float)\n",
    "xs     = torch.zeros((imgs.shape[0],1,imgs.shape[1],imgs.shape[2]),dtype=torch.float)\n",
    "for ind in range(imgs.shape[0]):\n",
    "    imgs[ind,:,:] = imgs[ind,:,:]/torch.max(torch.abs(imgs[ind,:,:]))\n",
    "    y = torch.fft.fftshift(F.fftn(imgs[ind,:,:],dim=(0,1),norm='ortho'))\n",
    "    ysub = torch.zeros(y.shape,dtype=y.dtype)\n",
    "    ysub[mask_lf==1,:] = y[mask_lf==1,:]\n",
    "    xs[ind,0,:,:] = torch.abs(F.ifftn(torch.fft.ifftshift(ysub),dim=(0,1),norm='ortho')) \n",
    "\n",
    "    yfulls[ind,0,:,:] = torch.real(y)\n",
    "    yfulls[ind,1,:,:] = torch.imag(y)\n",
    "    ys[ind,:,mask_lf==1,:] = yfulls[ind,:,mask_lf==1,:]\n",
    "\n",
    "labels = torch.tensor( np.load('/home/huangz78/data/data_gt_greedymask.npz')['mask'].T ) # labels are already rolled\n",
    "\n",
    "imgNum = imgs.shape[0]\n",
    "traininds, testinds = train_test_split(np.arange(imgNum),random_state=0,shuffle=True,train_size=round(imgNum*0.8))\n",
    "test_total  = testinds.size\n",
    "\n",
    "traindata   = ys[traininds,:,:,:]\n",
    "valdata     = ys[testinds[0:test_total//2],:,:,:]\n",
    "\n",
    "trainlabels = mask_filter(labels[traininds,:],base=base)\n",
    "vallabels   = mask_filter(labels[testinds[0:test_total//2],:],base=base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bb1c9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgind = 19\n",
    "testimg  = valdata[imgind,:,:,:]\n",
    "output_1 = net(testimg.view(-1,2,320,320))\n",
    "binary_1 = sigmoid_binarize(output_1)[0,:]\n",
    "greedy_1 = vallabels[imgind,:]\n",
    "\n",
    "imgind = 13\n",
    "testimg = valdata[imgind,:,:,:]\n",
    "output_2 = net(testimg.view(-1,2,320,320))\n",
    "binary_2 = sigmoid_binarize(output_2)[0,:]\n",
    "greedy_2 = vallabels[imgind,:]\n",
    "\n",
    "print(torch.sum(torch.abs(binary_1-binary_2)))\n",
    "print(output_1 - output_2)\n",
    "# sigmoid_binarize(output)[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61dab5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import mask_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef182d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_1 = mask_complete(binary_1.view(1,-1),320,rolled=True)\n",
    "kplot(mask_1.view(-1))\n",
    "kplot(greedy_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189a1e93",
   "metadata": {},
   "source": [
    "# mnet quality check: x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcc99bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnet_weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    print(m)\n",
    "    if classname.find('Conv2d') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8267a970",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate a mnet mask as an example\n",
    "\n",
    "mnet = MNet(out_size=320-24)\n",
    "checkpoint = torch.load('/home/huangz78/checkpoints/mnet_split_trained.pth')\n",
    "mnet.load_state_dict(checkpoint['model_state_dict'])\n",
    "print('MNet loaded successfully from: ' + '/home/huangz78/checkpoints/mnet_split_trained.pth')\n",
    "\n",
    "test_dir = '/home/huangz78/data/testdata_x.npz'\n",
    "# testimg  = torch.tensor(np.load(test_dir)['x']) \n",
    "# print(testimg.shape)\n",
    "# test_sub  = test_sub[0:10,:,:]\n",
    "test_full = torch.tensor(np.load(test_dir)['xfull']) \n",
    "mask_greedy = np.load('/home/huangz78/data/data_gt_greedymask.npz')\n",
    "mask_greedy = mask_greedy['mask'].T # this greedy mask is rolled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634a1d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(utils)\n",
    "from utils import mnet_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae4fcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgind = np.random.randint(test_full.shape[0])\n",
    "mnet.train()\n",
    "imgind1 = np.random.randint(199)\n",
    "print('current selected image is indexed: ',imgind1)\n",
    "img1 = test_full[imgind1,:,:]\n",
    "imgind2 = np.random.randint(199)\n",
    "print('current selected image is indexed: ',imgind2)\n",
    "img2 = test_full[imgind2,:,:]\n",
    "# plt.imshow(img)\n",
    "# plt.show()\n",
    "\n",
    "budget = 56\n",
    "lowfreqmask,_,_ = mask_naiveRand(img1.shape[0],fix=24,other=0,roll=True)\n",
    "# randmask,_,_ = mask_naiveRand(img.shape[0],fix=24,other=budget,roll=True)\n",
    "# kplot(randmask)\n",
    "\n",
    "yfull1 = torch.fft.fftshift(F.fftn(img1,dim=(0,1),norm='ortho')) # y is ROLLED in this line!\n",
    "yfull2 = torch.fft.fftshift(F.fftn(img2,dim=(0,1),norm='ortho')) # y is ROLLED!\n",
    "yfull  = torch.stack((yfull1,yfull2),dim=0)\n",
    "# x_lf_minus      = -x_lf.clone()\n",
    "x_lf   = get_x_f_from_yfull(lowfreqmask,yfull,DTyp=torch.cfloat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9239be",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnet( x_lf.view(x_lf.shape[0],1,img1.shape[0],img1.shape[1]) ).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6633587",
   "metadata": {},
   "outputs": [],
   "source": [
    "yfull1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba88660",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnet.eval()\n",
    "mnetmask = mnet( 1e3*torch.randn(10,1,img1.shape[0],img1.shape[1]) )\n",
    "# x_lf =  1e3*torch.randn(10,img1.shape[0],img1.shape[1]) \n",
    "# highmask_raw = mnet( x_lf.view(x_lf.shape[0],1,img1.shape[0],img1.shape[1]) )\n",
    "# mnetmask = mnet_wrapper(mnet,x_lf,budget,img1.shape)\n",
    "print(mnetmask.shape)\n",
    "\n",
    "torch.sum( torch.abs( mnetmask[0,:] - mnetmask[1,:] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0f2b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(2,2,4,5)\n",
    "b = torch.randn(2,2,4,5)\n",
    "c = a[:,0,:,:] + b[:,1,:,:]\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb164451",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "highmask_raw  = mnet( x_lf.view(x_lf.shape[0],1,img1.shape[0],img1.shape[1]) ).view(-1)  # no sigmoid \n",
    "# highmask_raw  = mnet( 1e10*torch.randn(1,1,img.shape[0],img.shape[1]) ).view(-1)  # no sigmoid \n",
    "# print('highmask_raw = ', highmask_raw)\n",
    "plt.plot(highmask_raw.detach().numpy())\n",
    "plt.show()\n",
    "mnetmask = mnet_wrapper(mnet,x_lf,budget,img.shape)\n",
    "kplot(mnetmask)\n",
    "kplot(mask_greedy[imgind,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be829245",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(mnet.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6157408e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for param in mnet.named_parameters():\n",
    "      print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c332241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnetmask_old = mnetmask.clone()\n",
    "mnetmask - mnetmask_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07beece8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "randqual[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36586c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show quality of mnet\n",
    "filepath = '/home/huangz78/checkpoints/alternating_update_error_track.npz'\n",
    "data_loss = np.load(filepath)\n",
    "\n",
    "print(data_loss.files)\n",
    "\n",
    "randqual   = data_loss['randqual']\n",
    "mnetqual   = data_loss['mnetqual']\n",
    "greedyqual = data_loss['greedyqual']\n",
    "randspar   = data_loss['randspar']\n",
    "mnetspar   = data_loss['mnetspar']\n",
    "\n",
    "try:\n",
    "    visualization(randqual[1:],mnetqual[1:],greedyqual=greedyqual,\\\n",
    "             randspar=randspar,mnetspar=mnetspar,greedyspar=greedyspar*np.ones(len(greedyqual)))\n",
    "except Exception:\n",
    "    visualization(randqual[1:],mnetqual[1:],randspar=randspar,mnetspar=mnetspar,log1=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
