{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23117fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.fft as F\n",
    "from importlib import reload\n",
    "from torch.nn.functional import relu\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Func\n",
    "import torch.optim as optim\n",
    "import utils\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import copy\n",
    "\n",
    "from utils import kplot,mask_naiveRand,mask_filter, get_x_f_from_yfull\n",
    "from mnet import MNet\n",
    "\n",
    "from mask_backward_new import mask_backward, mask_eval\n",
    "from utils import mask_complete, mask_makebinary,kplot, mask_filter, mask_makebinary,raw_normalize, visualization\n",
    "\n",
    "sys.path.insert(0,'/home/huangz78/mri/unet/')\n",
    "from unet_model import UNet\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3209c8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNet loaded successfully from: /home/huangz78/checkpoints/mnet.pth\n"
     ]
    }
   ],
   "source": [
    "# load a mnet\n",
    "mnet = MNet(out_size=320-24)\n",
    "checkpoint = torch.load('/home/huangz78/checkpoints/mnet.pth')\n",
    "mnet.load_state_dict(checkpoint['model_state_dict'])\n",
    "print('MNet loaded successfully from: ' + '/home/huangz78/checkpoints/mnet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d978add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unet loaded successfully from : /home/huangz78/checkpoints/unet_1.pth\n"
     ]
    }
   ],
   "source": [
    "# load a unet for maskbackward\n",
    "UNET =  UNet(n_channels=1,n_classes=1,bilinear=True,skip=False)\n",
    "checkpoint = torch.load('/home/huangz78/checkpoints/unet_'+ str(UNET.n_channels) +'.pth')\n",
    "UNET.load_state_dict(checkpoint['model_state_dict'])\n",
    "print('Unet loaded successfully from : ' + '/home/huangz78/checkpoints/unet_'+ str(UNET.n_channels) +'.pth' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92dd9198",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/home/huangz78/data/traindata_x.npz'\n",
    "# train_sub = np.load(train_dir)['x']\n",
    "train_full = np.load(train_dir)['xfull']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0085689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullmask = torch.fft.fftshift(torch.tensor(np.load(train_dir)['mask'])) # roll the input mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19543a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([199, 320, 320])\n",
      "(199, 320)\n"
     ]
    }
   ],
   "source": [
    "test_dir = '/home/huangz78/data/testdata_x.npz'\n",
    "testimg  = torch.tensor(np.load(test_dir)['x']) \n",
    "print(testimg.shape)\n",
    "# test_sub  = test_sub[0:10,:,:]\n",
    "# test_full = torch.tensor(np.load(test_dir)['xfull']) \n",
    "mask_greedy = np.load('/home/huangz78/data/data_gt_greedymask.npz')\n",
    "mask_greedy = mask_greedy['mask'].T # this greedy mask is rolled\n",
    "print(mask_greedy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddeb9f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select an image whose greedy mask we have\n",
    "# test_dir  = '/home/huangz78/data/data_gt.npz'\n",
    "# test_full = torch.tensor( np.transpose(np.load(test_dir)['imgdata'],axes=(2,0,1)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a13dab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import visualization\n",
    "def alternating_update_with_unetRecon(mnet,unet,trainfulls,testimg,mask_init,mask_init_full=True,\\\n",
    "                                      maxIter_mb=50,evalmode='unet',alpha=2.8*1e-5,c=0.05,\\\n",
    "                                      lr_mb=1e-4,lr_mn=1e-4,maxRep=5,\\\n",
    "                                      corefreq=16,budget=48,plot=False,verbose=False,mask_greedy=None,\\\n",
    "                                      change_initmask=True,validate_every=10,dtyp=torch.float):\n",
    "    '''\n",
    "    alpha: magnitude of l1 penalty for high-frequency mask\n",
    "    '''\n",
    "    if mask_init_full:\n",
    "        fullmask = torch.tensor(mask_init).clone()\n",
    "        highmask = mask_filter(fullmask,base=corefreq,roll=True)\n",
    "    else:\n",
    "        fullmask = mask_complete(torch.tensor(mask_init),trainfulls.shape[1],rolled=True,dtyp=dtyp)\n",
    "        highmask = torch.tensor(mask_init).clone()\n",
    "    DTyp = torch.cfloat if dtyp==torch.float else torch.cdouble\n",
    "    criterion_mnet = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    optimizer_m = optim.RMSprop(mnet.parameters(), lr=lr_mn, weight_decay=0, momentum=0)\n",
    "    # optimizer_u = ......\n",
    "    \n",
    "    unet_eval = UNet(n_channels=1,n_classes=1,bilinear=True,skip=False)\n",
    "    unet_eval = copy.deepcopy(unet)\n",
    "    unet_eval.eval()\n",
    "    # training loop\n",
    "    global_step = 0; val_step = 0\n",
    "    qual_len = int(trainfulls.shape[0]//validate_every) if trainfulls.shape[0]%validate_every==0 else int(trainfulls.shape[0]//validate_every)+1\n",
    "    randqual = np.zeros((qual_len)); mnetqual = np.zeros((qual_len))\n",
    "    randspar = np.zeros((qual_len)); mnetspar = np.zeros((qual_len))\n",
    "    if mask_greedy is not None:\n",
    "        greedyqual = np.zeros((qual_len))\n",
    "        greedyspar = np.ones((qual_len)) * np.sum(mask_greedy[0,:])/trainfulls.shape[1]\n",
    "    else:\n",
    "        greedyqual = None; greedyspar = None\n",
    "    \n",
    "    for xstar in trainfulls:\n",
    "        xstar = torch.tensor(xstar,dtype=dtyp)\n",
    "        yfull = torch.fft.fftshift(F.fftn(xstar,dim=(0,1),norm='ortho')) # y is ROLLED!\n",
    "        lowfreqmask,_,_ = mask_naiveRand(xstar.shape[0],fix=corefreq,other=0,roll=True)\n",
    "        x_lf            = get_x_f_from_yfull(lowfreqmask,yfull)\n",
    "        ########################################  \n",
    "        ## (1) mask_backward\n",
    "        ########################################        \n",
    "        if change_initmask and global_step>0: # option 2: highmask = mask_pred from step (2)\n",
    "            highmask = mnet(x_lf.view(1,1,xstar.shape[0],xstar.shape[1])).view(-1)\n",
    "        highmask_refined,unet = mask_backward(highmask,xstar,unet=unet, mnet=mnet,\\\n",
    "                          beta=1.,alpha=alpha,c=c,\\\n",
    "                          maxIter=maxIter_mb,seed=0,break_limit=maxIter_mb//2,\\\n",
    "                          lr=lr_mb,mode='UNET',budget=budget,normalize=True,\\\n",
    "                          verbose=verbose,dtyp=torch.float)        \n",
    "        ########################################  \n",
    "        ## (2) update mnet\n",
    "        ########################################        \n",
    "        mnet.train()\n",
    "        unet.eval()\n",
    "        rep = 0\n",
    "        while rep < maxRep:\n",
    "            mask_pred  = mnet(x_lf.view(1,1,xstar.shape[0],xstar.shape[1]))\n",
    "            mask_pred_full = mask_complete(mask_pred.view(-1),xstar.shape[0],rolled=True,dtyp=dtyp)\n",
    "            x_lf_new   = get_x_f_from_yfull(mask_pred_full,yfull).view(1,1,xstar.shape[0],xstar.shape[1])\n",
    "            x_unet     = unet(x_lf_new)\n",
    "            train_loss = criterion_mnet(mask_pred,highmask_refined.view(mask_pred.shape))\n",
    "            optimizer_m.zero_grad()\n",
    "            # optimizer step wrt unet parameters ?\n",
    "            train_loss.backward()\n",
    "            optimizer_m.step()\n",
    "            rep += 1\n",
    "        mnet.eval()             \n",
    "        ########################################  \n",
    "        ## (3) check mnet performance: does it beat random sampling?\n",
    "        ########################################\n",
    "        if (global_step%validate_every==0) or (global_step==trainfulls.shape[0]-1):\n",
    "            randqual_tmp = 0; mnetqual_tmp = 0; greedyqual_tmp = 0\n",
    "            randspar_tmp = 0; mnetspar_tmp = 0\n",
    "            imgind = 0\n",
    "            for img in testimg:\n",
    "#                 img    = torch.tensor(img,dtype=dtyp) # now we test on 1 image only.\n",
    "#                 yfull_test = torch.fft.fftshift(F.fftn(img,dim=(0,1),norm='ortho'))\n",
    "#                 x_test_lf  = get_x_f_from_yfull(lowfreqmask,yfull_test)\n",
    "                x_test_lf     = img\n",
    "                highmask_tmp  = torch.sigmoid( mnet( x_test_lf.view(1,1,img.shape[0],img.shape[1]) ).view(-1) )   \n",
    "                highmask_test = mask_makebinary( raw_normalize(highmask_tmp,budget) , sigma=False )\n",
    "\n",
    "                mask_rand,_,_ = mask_naiveRand(xstar.shape[0],fix=corefreq,other=highmask_test.sum(),roll=True)\n",
    "                mask_test     = mask_complete(highmask_test.view(-1),xstar.shape[0],rolled=True,dtyp=dtyp)\n",
    "                \n",
    "                randqual_img  = mask_eval(mask_rand,img,UNET=unet_eval)\n",
    "                mnetqual_img  = mask_eval(mask_test,img,UNET=unet_eval)\n",
    "                \n",
    "                randqual_tmp += randqual_img\n",
    "                mnetqual_tmp += mnetqual_img\n",
    "                \n",
    "                if verbose:\n",
    "                    print('Quality of random mask : ', randqual_img) # UNET=unet_eval\n",
    "                    print('Quality of mnet   mask : ', mnetqual_img) # UNET=unet_eval\n",
    "                if mask_greedy is not None:\n",
    "                    greedyqual_img = mask_eval(mask_greedy[imgind,:],img,UNET=unet_eval)\n",
    "                    if verbose:\n",
    "                        print('Quality of greedy mask : ', greedyqual_img)\n",
    "                    greedyqual_tmp += greedyqual_img\n",
    "                    randspar_tmp += mask_rand.sum().item()/xstar.shape[0]\n",
    "                    mnetspar_tmp += mask_test.sum().item()/xstar.shape[0]\n",
    "                    if verbose:\n",
    "                        print(f'sparsity of random mask: {mask_rand.sum().item()/xstar.shape[0]},\\\n",
    "                                mnet mask: {mask_test.sum().item()/xstar.shape[0]}, \\\n",
    "                                greedy mask: {np.sum(mask_greedy[imgind,:])/xstar.shape[0]}')\n",
    "                else:\n",
    "                    randspar_tmp += mask_rand.sum().item()/xstar.shape[0]\n",
    "                    mnetspar_tmp += mask_test.sum().item()/xstar.shape[0]\n",
    "                    if verbose:\n",
    "                        print(f'sparsity of random mask: {mask_rand.sum().item()/xstar.shape[0]},\\\n",
    "                            mnet mask: {mask_test.sum().item()/xstar.shape[0]}')\n",
    "                if verbose:\n",
    "                    print('\\n')\n",
    "                imgind += 1\n",
    "            randqual[val_step] = randqual_tmp/testimg.shape[0]\n",
    "            mnetqual[val_step] = mnetqual_tmp/testimg.shape[0]\n",
    "            if mask_greedy is not None:\n",
    "                greedyqual[val_step] = greedyqual_tmp/testimg.shape[0]\n",
    "            randspar[val_step] = randspar_tmp/testimg.shape[0]\n",
    "            mnetspar[val_step] = mnetspar_tmp/testimg.shape[0]\n",
    "            val_step += 1\n",
    "            if plot:\n",
    "                visualization(randqual,mnetqual,greedyqual=greedyqual,\\\n",
    "                             randspar=randspar,mnetspar=mnetspar,greedyspar=greedyspar)\n",
    "        global_step += 1\n",
    "    # return mnet, unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8c0db6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/pyenv/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/huangz78/mri/mask_backward_new.py:121: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  xstar = torch.tensor(xstar,dtype=dtyp); highmask = torch.tensor(highmask,dtype=dtyp)\n",
      "/home/huangz78/mri/mask_backward_new.py:134: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fullmask = torch.tensor( mask_complete(M_high,imgHeg,dtyp=dtyp) )\n"
     ]
    }
   ],
   "source": [
    "alternating_update_with_unetRecon(mnet,UNET,train_full,testimg,fullmask,\\\n",
    "                                  alpha=3e-4,c=1e-2,lr_mb=1e-4,lr_mn=1e-4,\\\n",
    "                                  maxIter_mb=50,maxRep=5,\\\n",
    "                                  corefreq=24,budget=24,\\\n",
    "                                  mask_greedy=mask_greedy,change_initmask=True,\\\n",
    "                                  verbose=True,plot=True,validate_every=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e1fee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(utils)\n",
    "import mask_backward_new\n",
    "reload(mask_backward_new)\n",
    "from mask_backward_new import mask_backward\n",
    "from utils import raw_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266a9f21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
