{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae002028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import torch\n",
    "import torch.fft as F\n",
    "from importlib import reload\n",
    "from torch.nn.functional import relu\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Func\n",
    "import torch.optim as optim\n",
    "import utils,mask_backward_new\n",
    "import matplotlib.pyplot as plt\n",
    "# from maskbackward import mask_backward\n",
    "from mask_backward_new import mask_backward, mask_eval\n",
    "from utils import mask_complete , mask_makebinary,kplot, mask_filter\n",
    "from utils import get_x_f_from_yfull,mask_naiveRand, apply_mask, sigmoid_binarize\n",
    "\n",
    "sys.path.insert(0,'/home/huangz78/mri/unet/')\n",
    "from unet_model import UNet\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfd9d05",
   "metadata": {},
   "source": [
    "#### import data to test mask_backward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70d3ccb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_gt = np.load('/home/huangz78/data/data_gt.npz')\n",
    "# datafornn = np.load('/home/huangz78/data/datafornn.npz')\n",
    "data = np.load('/home/huangz78/data/traindata_x.npz')\n",
    "dtyp = torch.float\n",
    "xfull = torch.tensor(data['xfull'],dtype=dtyp)\n",
    "fullmask = torch.tensor(data['mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98079236",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNet loaded successfully from: /home/huangz78/checkpoints/mnet.pth\n",
      "Unet loaded successfully from: /home/huangz78/checkpoints/unet_1.pth\n",
      "nn's are ready\n"
     ]
    }
   ],
   "source": [
    "# load a mnet\n",
    "from mnet import MNet\n",
    "# mnet = MNet(out_size=320-24)\n",
    "mnet = MNet(beta=1,in_channels=2,out_size=320-24, imgsize=(320,320),poolk=3)\n",
    "checkpoint = torch.load('/home/huangz78/checkpoints/mnet.pth')\n",
    "mnet.load_state_dict(checkpoint['model_state_dict'])\n",
    "print('MNet loaded successfully from: ' + '/home/huangz78/checkpoints/mnet.pth')\n",
    "mnet.eval()\n",
    "# load a unet for maskbackward\n",
    "UNET =  UNet(n_channels=1,n_classes=1,bilinear=True,skip=False)\n",
    "checkpoint = torch.load('/home/huangz78/checkpoints/unet_'+ str(UNET.n_channels) +'.pth')\n",
    "UNET.load_state_dict(checkpoint['model_state_dict'])\n",
    "print('Unet loaded successfully from: ' + '/home/huangz78/checkpoints/unet_'+ str(UNET.n_channels) +'.pth' )\n",
    "UNET.train()\n",
    "print('nn\\'s are ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa189d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload(utils)\n",
    "# from utils import sigmoid_binarize\n",
    "reload(mask_backward_new)\n",
    "from mask_backward_new import mask_backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65fe3d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 5\n",
    "xstar = xfull[0:batchsize,:,:]\n",
    "\n",
    "corefreq = 24\n",
    "yfull = torch.fft.fftshift(F.fftn(xstar,dim=(1,2),norm='ortho')) # y is ROLLED!\n",
    "lowfreqmask,_,_ = mask_naiveRand(xstar.shape[1],fix=corefreq,other=0,roll=True)\n",
    "\n",
    "z        = apply_mask(lowfreqmask,yfull)\n",
    "highmask = sigmoid_binarize(mnet(z))\n",
    "# x_lf     = get_x_f_from_yfull(lowfreqmask,yfull)\n",
    "# highmask = sigmoid_binarize(mnet(x_lf.view(batchsize,1,xstar.shape[1],xstar.shape[2])))\n",
    "\n",
    "NN         = 14\n",
    "alpha_grid = 10**(np.linspace(-6,0,NN))\n",
    "c_grid     = np.array([1e-4,1e-3,1e-2,1e-1,1e0])\n",
    "maskloss = np.zeros((NN,5))\n",
    "sparsity = np.zeros((NN,5))\n",
    "########################################  \n",
    "## (1) mask_backward\n",
    "########################################    \n",
    "maxIter_mb = 10\n",
    "lr_mb      = 1e-2\n",
    "budget     = 56\n",
    "# alpha = 1e-5\n",
    "# c = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb9468f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/huangz78/mri/mask_backward_new.py\u001b[0m(217)\u001b[0;36mmask_backward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    215 \u001b[0;31m        \u001b[0mfullmask_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_makebinary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfullmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    216 \u001b[0;31m        \u001b[0mbreakpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 217 \u001b[0;31m        \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    218 \u001b[0;31m        \u001b[0mM_high\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproj_eps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM_high\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# soft-hard-thresholding as postprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    219 \u001b[0;31m        \u001b[0mfullmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM_high\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimgHeg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtyp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> p M_high[0,:]\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
      "        1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<SliceBackward>)\n",
      "ipdb> p M_high.grad[0,:]\n",
      "tensor([-4.5762e-05, -5.9039e-05, -5.7960e-05, -6.6076e-05, -6.1090e-05,\n",
      "        -6.9848e-05, -6.3156e-05, -6.9728e-05, -6.2052e-05, -7.3373e-05,\n",
      "        -6.0763e-05, -7.3946e-05, -7.0080e-05, -8.6955e-05, -7.5697e-05,\n",
      "        -7.6395e-05, -7.3801e-05, -8.0446e-05, -7.7165e-05, -8.1714e-05,\n",
      "        -7.9091e-05, -8.2253e-05, -7.1902e-05, -7.3912e-05, -8.4211e-05,\n",
      "        -8.5809e-05, -8.5302e-05, -9.0477e-05, -8.6471e-05, -8.7744e-05,\n",
      "        -9.7541e-05, -1.1288e-04, -9.3017e-05, -8.8689e-05, -9.8899e-05,\n",
      "        -9.6651e-05, -9.6523e-05, -9.6687e-05, -1.0558e-04, -1.0325e-04,\n",
      "        -1.1234e-04, -9.8760e-05, -9.6739e-05, -1.0229e-04, -1.0882e-04,\n",
      "        -1.0233e-04, -1.1603e-04, -1.1439e-04, -1.1182e-04, -1.3274e-04,\n",
      "        -1.2512e-04, -1.1394e-04, -1.3206e-04, -1.1413e-04, -1.1636e-04,\n",
      "        -1.0611e-04, -1.2232e-04, -1.0599e-04,  1.0000e+06, -1.2748e-04,\n",
      "        -1.1624e-04, -1.2587e-04, -1.2453e-04, -1.2106e-04, -1.4052e-04,\n",
      "        -1.3406e-04, -1.3157e-04, -1.3775e-04, -1.3754e-04, -1.4248e-04,\n",
      "        -1.4614e-04, -1.4124e-04, -1.5457e-04, -1.7314e-04, -1.6467e-04,\n",
      "        -1.5180e-04, -1.6971e-04, -1.5975e-04, -1.6184e-04, -1.6937e-04,\n",
      "        -1.7029e-04, -1.9070e-04, -1.6415e-04, -1.7716e-04, -2.0065e-04,\n",
      "        -2.7018e-05,  1.0000e+06, -1.7286e-04, -1.6780e-04, -1.6981e-04,\n",
      "        -1.7692e-04,  1.0000e+06,  1.0000e+06,  1.0000e+06,  1.0000e+06,\n",
      "        -1.5202e-04,  1.0000e+06,  1.0000e+06,  1.0000e+06,  1.0000e+06,\n",
      "         1.0000e+06, -1.4945e-04,  1.0000e+06,  1.0000e+06,  1.0000e+06,\n",
      "         1.0000e+06, -1.8899e-04, -1.6735e-04,  1.0000e+06,  1.0000e+06,\n",
      "         1.0000e+06, -1.9510e-04, -2.3093e-04, -2.7547e-04, -2.3910e-04,\n",
      "        -2.6903e-04, -2.2496e-04, -2.6388e-04, -2.6858e-04, -2.6708e-04,\n",
      "        -2.5819e-04, -2.5988e-04, -2.5643e-04,  1.0000e+06,  1.0000e+06,\n",
      "         1.0000e+06, -2.7274e-04,  1.0000e+06,  1.0000e+06,  1.0000e+06,\n",
      "         1.0000e+06,  1.0000e+06,  1.0000e+06,  1.0000e+06,  1.0000e+06,\n",
      "         1.0000e+06,  1.0000e+06,  1.0000e+06,  1.0000e+06,  1.0000e+06,\n",
      "         1.0000e+06,  1.0000e+06,  1.0000e+06,  1.0000e+06,  1.0000e+06,\n",
      "         1.0000e+06,  1.0000e+06,  1.0000e+06,  1.0000e+06,  1.0000e+06,\n",
      "         1.0000e+06,  1.0000e+06,  1.0000e+06,  1.0000e+06,  1.0000e+06,\n",
      "         1.0000e+06,  1.0000e+06,  1.0000e+06,  1.0000e+06,  1.0000e+06,\n",
      "         1.0000e+06,  1.0000e+06,  1.0000e+06,  1.0000e+06,  1.0000e+06,\n",
      "         1.0000e+06,  1.0000e+06,  1.0000e+06,  1.0000e+06,  1.0000e+06,\n",
      "        -2.7314e-04,  1.0000e+06,  1.0000e+06,  1.0000e+06, -2.5657e-04,\n",
      "        -2.6003e-04, -2.5815e-04, -2.6724e-04, -2.6839e-04, -2.6380e-04,\n",
      "        -2.2504e-04, -2.6890e-04, -2.3888e-04, -2.7547e-04, -2.3052e-04,\n",
      "        -1.9501e-04,  1.0000e+06,  1.0000e+06,  1.0000e+06, -1.6716e-04,\n",
      "        -1.8870e-04,  1.0000e+06,  1.0000e+06,  1.0000e+06, -4.1827e-05,\n",
      "        -1.4946e-04,  1.0000e+06,  1.0000e+06,  1.0000e+06,  1.0000e+06,\n",
      "         1.0000e+06, -1.5181e-04, -2.4570e-05,  1.0000e+06,  1.0000e+06,\n",
      "         1.0000e+06, -1.7681e-04, -1.6985e-04, -1.6786e-04, -1.7295e-04,\n",
      "         1.0000e+06,  1.0000e+06, -2.0086e-04, -1.7698e-04, -1.6417e-04,\n",
      "        -1.9074e-04, -1.7032e-04, -1.6924e-04, -1.6188e-04, -1.5980e-04,\n",
      "        -1.6977e-04, -1.5173e-04, -1.6468e-04, -1.7321e-04, -1.5433e-04,\n",
      "        -1.4129e-04, -1.4630e-04, -1.4251e-04, -1.3756e-04, -1.3778e-04,\n",
      "        -1.3155e-04, -1.3405e-04, -1.4056e-04, -1.2104e-04, -1.2453e-04,\n",
      "        -1.2589e-04, -1.1643e-04, -1.2749e-04,  1.0000e+06, -1.0594e-04,\n",
      "        -1.2239e-04, -1.0618e-04, -1.1653e-04, -1.1410e-04, -1.3196e-04,\n",
      "        -1.1386e-04, -1.2512e-04, -1.3281e-04, -1.1193e-04, -1.1442e-04,\n",
      "        -1.1607e-04, -1.0222e-04, -1.0877e-04, -1.0218e-04, -9.6703e-05,\n",
      "        -9.8708e-05, -1.1219e-04, -1.0319e-04, -1.0529e-04, -9.6740e-05,\n",
      "        -9.6601e-05, -9.6676e-05, -9.8984e-05, -8.8763e-05, -9.2994e-05,\n",
      "        -1.1293e-04, -9.7625e-05, -8.7634e-05, -8.6576e-05, -9.0452e-05,\n",
      "        -8.5362e-05, -8.5806e-05, -8.4469e-05, -7.3785e-05, -7.1963e-05,\n",
      "        -8.2402e-05, -7.9018e-05, -8.1822e-05, -7.7097e-05, -8.0323e-05,\n",
      "        -7.3680e-05, -7.6475e-05, -7.5700e-05, -8.6825e-05, -6.9933e-05,\n",
      "        -7.4004e-05, -6.0727e-05, -7.3261e-05, -6.2226e-05, -6.9743e-05,\n",
      "        -6.3206e-05, -6.9869e-05, -6.1327e-05, -6.5995e-05, -5.8021e-05,\n",
      "        -5.9099e-05])\n",
      "ipdb> list\n",
      "\u001b[1;32m    212 \u001b[0m                \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    213 \u001b[0m        \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    214 \u001b[0m        \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    215 \u001b[0m        \u001b[0mfullmask_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_makebinary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfullmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    216 \u001b[0m        \u001b[0mbreakpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 217 \u001b[0;31m        \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    218 \u001b[0m        \u001b[0mM_high\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproj_eps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM_high\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# soft-hard-thresholding as postprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    219 \u001b[0m        \u001b[0mfullmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM_high\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimgHeg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtyp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    220 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    221 \u001b[0m        \u001b[0;31m#################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    222 \u001b[0m        \u001b[0;31m## track training process, and printing information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> n\n",
      "> \u001b[0;32m/home/huangz78/mri/mask_backward_new.py\u001b[0m(218)\u001b[0;36mmask_backward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    216 \u001b[0;31m        \u001b[0mbreakpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    217 \u001b[0;31m        \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 218 \u001b[0;31m        \u001b[0mM_high\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproj_eps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM_high\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# soft-hard-thresholding as postprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    219 \u001b[0;31m        \u001b[0mfullmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM_high\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimgHeg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtyp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    220 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> p M_high[0,:]\n",
      "tensor([0.0998, 0.0998, 0.0998, 0.0998, 0.0998, 0.0999, 0.0998, 0.0999, 0.0998,\n",
      "        0.0999, 0.0998, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999,\n",
      "        0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999,\n",
      "        0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999,\n",
      "        0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999,\n",
      "        0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999,\n",
      "        0.0999, 0.0999, 0.0999, 0.0999, 0.9000, 0.0999, 0.0999, 0.0999, 0.0999,\n",
      "        0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999,\n",
      "        0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999,\n",
      "        0.0999, 0.0999, 0.0999, 0.1000, 0.0996, 0.9000, 0.0999, 0.0999, 0.0999,\n",
      "        0.0999, 0.9000, 0.9000, 0.9000, 0.9000, 0.0999, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.0999, 0.9000, 0.9000, 0.9000, 0.9000, 0.0999, 0.0999,\n",
      "        0.9000, 0.9000, 0.9000, 0.0999, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.9000, 0.9000, 0.9000,\n",
      "        0.1000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.1000,\n",
      "        0.9000, 0.9000, 0.9000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.0999, 0.9000, 0.9000, 0.9000,\n",
      "        0.0999, 0.0999, 0.9000, 0.9000, 0.9000, 0.0998, 0.0999, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.0999, 0.0996, 0.9000, 0.9000, 0.9000, 0.0999,\n",
      "        0.0999, 0.0999, 0.0999, 0.9000, 0.9000, 0.1000, 0.0999, 0.0999, 0.0999,\n",
      "        0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999,\n",
      "        0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999,\n",
      "        0.0999, 0.0999, 0.0999, 0.0999, 0.9000, 0.0999, 0.0999, 0.0999, 0.0999,\n",
      "        0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999,\n",
      "        0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999,\n",
      "        0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999,\n",
      "        0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999,\n",
      "        0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0999, 0.0998, 0.0999,\n",
      "        0.0998, 0.0999, 0.0998, 0.0999, 0.0998, 0.0998, 0.0998, 0.0998],\n",
      "       grad_fn=<SliceBackward>)\n",
      "ipdb> q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-c0cb7acb85ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                           \u001b[0mmaxIter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxIter_mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbreak_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxIter_mb\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                           \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'UNET'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbudget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbudget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                           verbose=True,dtyp=torch.float,testmode=True)\n\u001b[0m",
      "\u001b[0;32m~/mri/mask_backward_new.py\u001b[0m in \u001b[0;36mmask_backward\u001b[0;34m(highmask, xstar, maxIter, seed, eps, normalize, budget, lr, weight_decay, momentum, beta, alpha, c, unet_mode, unet, mnet, unroll_block, Lambda, rho, mode, lr_Lambda, break_limit, print_every, verbose, save_cp, dtyp, testmode)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mbreakpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mM_high\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproj_eps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM_high\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# soft-hard-thresholding as postprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0mfullmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM_high\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimgHeg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtyp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mri/mask_backward_new.py\u001b[0m in \u001b[0;36mmask_backward\u001b[0;34m(highmask, xstar, maxIter, seed, eps, normalize, budget, lr, weight_decay, momentum, beta, alpha, c, unet_mode, unet, mnet, unroll_block, Lambda, rho, mode, lr_Lambda, break_limit, print_every, verbose, save_cp, dtyp, testmode)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mbreakpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mM_high\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproj_eps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM_high\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# soft-hard-thresholding as postprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0mfullmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM_high\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimgHeg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtyp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/pyenv/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/pyenv/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mask_backward(highmask,xstar,unet=UNET, mnet=mnet,\\\n",
    "                          beta=1.,alpha=1e6,c=0,\\\n",
    "                          maxIter=maxIter_mb,seed=0,break_limit=maxIter_mb*3//5,\\\n",
    "                          lr=1e-2,mode='UNET',budget=budget,normalize=False,\\\n",
    "                          verbose=True,dtyp=torch.float,testmode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40b55319",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unet loaded successfully from: /home/huangz78/checkpoints/unet_1.pth\n",
      "nn's are ready\n",
      "iter: 1, upper level loss: 0.13358692824840546\n",
      " changed rows in this batch: 0.0, loss of current mask: 24.932022392749786%\n",
      "samp. ratio: 0.30875, Recon. rel. err: 0.13314367830753326 \n",
      "\n",
      "Iter 6, rows added: 0.4, rows reducted: 0.6\n",
      "Iter 7, rows added: 3.2, rows reducted: 1.0\n",
      "Iter 8, rows added: 9.2, rows reducted: 1.8\n",
      "Iter 9, rows added: 14.8, rows reducted: 1.0\n",
      "\n",
      "return at Iter ind:  10\n",
      "loss of returned mask: 26.90894901752472%\n",
      "samp. ratio: 0.38125, Recon. rel. err: 0.03138349577784538 \n",
      "\n",
      "Unet loaded successfully from: /home/huangz78/checkpoints/unet_1.pth\n",
      "nn's are ready\n",
      "iter: 1, upper level loss: 0.13429537415504456\n",
      " changed rows in this batch: 0.0, loss of current mask: 24.932022392749786%\n",
      "samp. ratio: 0.30875, Recon. rel. err: 0.13314367830753326 \n",
      "\n",
      "Iter 6, rows added: 0.4, rows reducted: 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e11c4bb41987>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m                           \u001b[0mmaxIter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxIter_mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbreak_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxIter_mb\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                           \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr_mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'UNET'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbudget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbudget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                           verbose=True,dtyp=torch.float,testmode=True)\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0ma_ind\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mc_ind\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mri/mask_backward_new.py\u001b[0m in \u001b[0;36mmask_backward\u001b[0;34m(highmask, xstar, maxIter, seed, eps, normalize, budget, lr, weight_decay, momentum, beta, alpha, c, unet_mode, unet, mnet, unroll_block, Lambda, rho, mode, lr_Lambda, break_limit, print_every, verbose, save_cp, dtyp, testmode)\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mfullmask_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_makebinary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfullmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/pyenv/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/pyenv/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "c_ind = 0\n",
    "for c in c_grid:\n",
    "    a_ind = 0\n",
    "    for alpha in alpha_grid:\n",
    "        # load a unet for maskbackward\n",
    "        UNET = UNet(n_channels=1,n_classes=1,bilinear=True,skip=False)\n",
    "        checkpoint = torch.load('/home/huangz78/checkpoints/unet_'+ str(UNET.n_channels) +'.pth')\n",
    "        UNET.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print('Unet loaded successfully from: ' + '/home/huangz78/checkpoints/unet_'+ str(UNET.n_channels) +'.pth' )\n",
    "        UNET.train()\n",
    "        print('nn\\'s are ready')\n",
    "    # highmask_refined,unet = mask_backward(highmask,xstar,unet=UNET, mnet=mnet,\\\n",
    "    #                   beta=1.,alpha=alpha,c=c,\\\n",
    "    #                   maxIter=maxIter_mb,seed=0,break_limit=maxIter_mb*3//5,\\\n",
    "    #                   lr=lr_mb,mode='UNET',budget=budget,normalize=False,\\\n",
    "    #                   verbose=True,dtyp=torch.float)\n",
    "        maskloss[a_ind,c_ind],sparsity[a_ind,c_ind] = mask_backward(highmask,xstar,unet=UNET, mnet=mnet,\\\n",
    "                          beta=1.,alpha=alpha,c=c,\\\n",
    "                          maxIter=maxIter_mb,seed=0,break_limit=maxIter_mb*3//5,\\\n",
    "                          lr=lr_mb,mode='UNET',budget=budget,normalize=False,\\\n",
    "                          verbose=True,dtyp=torch.float,testmode=True)\n",
    "        a_ind += 1\n",
    "    c_ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a201eeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(alpha_grid,maskloss)\n",
    "plt.title('mask loss')\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(alpha_grid,sparsity,label='actual')\n",
    "plt.plot(alpha_grid,(corefreq+budget)/320*np.ones(alpha_grid.shape),label='target')\n",
    "plt.title('mask sparsity')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d9778b",
   "metadata": {},
   "outputs": [],
   "source": [
    "maskloss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64def9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = ['H', 'D', 'P', 'X','+']\n",
    "plt.figure(figsize=(10,8))\n",
    "for c_ind in range(len(c_grid)):\n",
    "    plt.plot(alpha_grid,maskloss[:,c_ind],label='c='+str(c_grid[c_ind]),marker=markers[c_ind],markersize=7)\n",
    "plt.xlabel('alpha')\n",
    "plt.title('mask loss')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "for c_ind in range(len(c_grid)):\n",
    "    plt.plot(alpha_grid,sparsity[:,c_ind],label='c='+str(c_grid[c_ind]),marker=markers[c_ind],markersize=7)\n",
    "plt.plot(alpha_grid,(corefreq+budget)/320*np.ones(alpha_grid.shape),'-.',label='target')\n",
    "plt.title('mask sparsity')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('alpha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf2a219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f07511",
   "metadata": {},
   "outputs": [],
   "source": [
    "(highmask_refined - highmask).abs().sum()\n",
    "\n",
    "ind = 0\n",
    "highmask_refined[ind,:] - highmask[ind,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f63436",
   "metadata": {},
   "source": [
    "### old tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c47134",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_gt = np.load('/home/huangz78/data/data_gt.npz')\n",
    "picind = np.random.randint(199)\n",
    "xstar = data_gt['imgdata'][:,:,27]\n",
    "xstar = xstar/np.max(np.abs(xstar))\n",
    "# highmask = datafornn['labels'][picind,:]\n",
    "plt.figure()\n",
    "plt.imshow(xstar)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77b872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload(maskbackward)\n",
    "# from maskbackward import mask_backward\n",
    "\n",
    "#mode UNET:\n",
    "\n",
    "reload(mask_backward_new)\n",
    "from mask_backward_new import mask_backward,mask_eval\n",
    "\n",
    "dtyp = torch.float\n",
    "# unroll_block = 8; Lambda=6.1e-4; rho=1e1\n",
    "\n",
    "# base = .05; expand = .15\n",
    "# highmask = torch.zeros((round(320*(1-base))),dtype=torch.double)\n",
    "# highmask[np.random.choice(round(320*(1-base)),round(320*expand),replace=False)] = 1\n",
    "\n",
    "highmask = mask_filter(fullmask,base=round(320*0.05),roll=True)\n",
    "print(highmask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26a2861",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = 1\n",
    "UNET =  UNet(n_channels=n_channels,n_classes=n_channels,bilinear=True,skip=False)\n",
    "checkpoint = torch.load('/home/huangz78/checkpoints/unet_' + str(n_channels) + '.pth')\n",
    "UNET.load_state_dict(checkpoint['model_state_dict'])\n",
    "UNET.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dd7ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## quick comparison between ifft recon and unet recon\n",
    "imgHeg = 320; imgWid = 320\n",
    "fullmask = torch.tensor( mask_complete(highmask,imgHeg,dtyp=torch.float) )\n",
    "kplot(fullmask)\n",
    "print('sparsity of fullmask = ',fullmask.sum().item()/imgHeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbf87f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xstar = torch.tensor(xstar,dtype=dtyp)\n",
    "DTyp = torch.cfloat if dtyp==torch.float else torch.cdouble\n",
    "y = torch.fft.fftshift(F.fftn(xstar,dim=(0,1),norm='ortho'))\n",
    "z = torch.fft.ifftshift(torch.tensordot(torch.diag(fullmask).to(DTyp),y,dims=([1],[0])))\n",
    "kplot(y,roll=False,log=True)\n",
    "kplot(z,roll=True,log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6bfa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgHeg = 320; imgWid = 320\n",
    "x_ifft = torch.abs(F.ifftn(z,dim=(0,1),norm='ortho')).to(dtyp)\n",
    "x_unet = UNET(x_ifft.view(1,1,imgHeg,imgWid)).detach()\n",
    "\n",
    "print('error of x_ifft = ', torch.norm(torch.flatten(x_ifft)-torch.flatten(xstar),'fro')/torch.norm(xstar,'fro') )\n",
    "print('error of x_unet = ', torch.norm(torch.flatten(x_unet)-torch.flatten(xstar),'fro')/torch.norm(xstar,'fro') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe675b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sigpy.mri.app import TotalVariationRecon\n",
    "NN = 50\n",
    "Lambda_grid = 10**np.linspace(-3.5,-3,NN)\n",
    "errRec = np.zeros((NN))\n",
    "ind = 1\n",
    "\n",
    "mps  = np.ones((1,imgHeg,imgWid))\n",
    "y_sp = np.reshape(z.numpy(),(-1,imgHeg,imgWid))\n",
    "for Lambda in Lambda_grid:\n",
    "# Lambda = 10**(-6.31) \n",
    "# Lambda = 10**(-3.2755) # np.log10(Lambda_grid[np.argmin(errRec)])\n",
    "    print('{} out of {}'.format(ind,NN))\n",
    "    x_sp = np.fft.fftshift( np.abs(TotalVariationRecon(y_sp, mps, Lambda,show_pbar=False).run()) ) \n",
    "    x_sp = torch.tensor(x_sp)\n",
    "    errRec[ind-1] = torch.norm(torch.flatten(x_sp)-torch.flatten(xstar),'fro')/torch.norm(xstar,'fro')\n",
    "    ind += 1\n",
    "#     print('error of x_sp = ', torch.norm(torch.flatten(x_sp)-torch.flatten(xstar),'fro')/torch.norm(xstar,'fro'))\n",
    "\n",
    "plt.figure()\n",
    "plt.xscale('log')\n",
    "plt.plot(Lambda_grid,errRec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b762a9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.linspace(-6,-4,gridnum)[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67057355",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reload(mask_backward_new)\n",
    "from mask_backward_new import mask_backward,mask_eval\n",
    "\n",
    "maxIter = 200\n",
    "gridnum = 10\n",
    "alpha_grid = 10**np.linspace(-4.6,-4.5,gridnum)\n",
    "sr_rec = np.zeros((gridnum))\n",
    "mloss_rec = np.zeros(gridnum)\n",
    "\n",
    "ind = 0\n",
    "for alpha in alpha_grid:\n",
    "    print('[{}/{}]  alpha {}'.format(ind+1,gridnum,alpha))\n",
    "    highmask_refined,refine_mloss,init_loss = mask_backward(highmask,xstar,\\\n",
    "                          beta=1., alpha=alpha,maxIter=maxIter,seed=0,break_limit=maxIter//2,\\\n",
    "                          lr=5e-4,mode='UNET',\\\n",
    "                          verbose=False,dtyp=dtyp)\n",
    "    print('Difference between masks: \\n',highmask_refined - highmask)\n",
    "#     print('Refined mask is: \\n',highmask_refined)\n",
    "    mloss_rec[ind] = refine_mloss\n",
    "    sr_rec[ind] = (torch.sum(highmask_refined).item() + 24)/320\n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bb4a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(alpha_grid,mloss_rec,label='refined')\n",
    "plt.scatter(alpha_grid,init_loss*np.ones(mloss_rec.shape),label='init.')\n",
    "plt.title('mask loss')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(alpha_grid,sr_rec,label='refined')\n",
    "plt.scatter(alpha_grid,0.25*np.ones(mloss_rec.shape),label='init.')\n",
    "plt.title('mask sampling ratio')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e5bf23",
   "metadata": {},
   "source": [
    "### arXiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f5e8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(mask_backward_new)\n",
    "from mask_backward_new import mask_backward\n",
    "\n",
    "# mode ADMM:\n",
    "\n",
    "highmask = torch.zeros((round(320*0.9)))\n",
    "highmask[np.random.choice(round(320*0.9),int(320*.1),replace=False)] = 1\n",
    "\n",
    "naive_mloss = mask_eval(mask_complete(highmask.to(torch.double),320),xstar,unroll_block=unroll_block,Lambda=Lambda,rho=rho) * 100\n",
    "highmask_refined,refine_mloss = mask_backward(highmask,xstar,\\\n",
    "                          beta=1., alpha=1e1,maxIter=200,unroll_block=unroll_block,seed=0,break_limit=100,\\\n",
    "                          lr=5e-4,mode='ADMM',Lambda=Lambda,rho=rho,\\\n",
    "                          verbose=True,perturb=False,perturb_freq=5,eps=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ce3038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vary sampling ratio, observe RMSE for the same image.\n",
    "reload(mask_backward_new)\n",
    "from mask_backward_new import mask_backward\n",
    "\n",
    "base=0.1\n",
    "r_grid = np.array([0.1,0.15,0.2])\n",
    "naive_mloss = np.zeros((r_grid.size))\n",
    "refine_mloss = np.zeros((r_grid.size))\n",
    "\n",
    "sampRatio = np.zeros((r_grid.size))\n",
    "\n",
    "unroll_block = 6; Lambda=6.1e-4; rho=1e1; lr = 5e-2\n",
    "maxIter = 300; break_limit = round(maxIter/3)\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "ind = 0\n",
    "for r in r_grid:\n",
    "    print('\\n r {}, the {} item out of {}'.format(r,ind+1,r_grid.size))\n",
    "    highmask = torch.zeros((round(320*(1-base))))\n",
    "    highmask[np.random.choice(round(320*(1-base)),int(320*r),replace=False)] = 1\n",
    "    \n",
    "    naive_mloss[ind] = mask_eval(mask_complete(highmask.to(torch.double),320),xstar,unroll_block=unroll_block,Lambda=Lambda,rho=rho) * 100\n",
    "    highmask_refined,refine_mloss[ind] = mask_backward(highmask,xstar,seed=0,\\\n",
    "                              beta=1., alpha=9.5e0,maxIter=maxIter,unroll_block=unroll_block,break_limit=break_limit,\\\n",
    "                              lr=lr,mode='ADMM',Lambda=Lambda,rho=rho,\\\n",
    "                              verbose=True,perturb=False,perturb_freq=5,eps=1e-2)\n",
    "    sampRatio[ind] = (highmask_refined.sum().item() + round(320*0.1))/320\n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63afc0ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('sampRatio: ',sampRatio)\n",
    "plt.figure()\n",
    "plt.scatter(r_grid,naive_mloss,label='naive')\n",
    "plt.scatter(sampRatio,refine_mloss,label='refined')\n",
    "plt.legend(bbox_to_anchor=(1.04,0.5), loc=\"center left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6355e5bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## find a good alpha for l1 penalty\n",
    "reload(mask_backward_new); reload(utils);\n",
    "from mask_backward_new import mask_backward\n",
    "alpha_grid = np.linspace(1,10,10)\n",
    "sparsity_ = np.zeros(alpha_grid.size)\n",
    "change_count = np.zeros(alpha_grid.size)\n",
    "\n",
    "unroll_block = 6; Lambda=6.1e-4; rho=1e1; lr = 5e-2\n",
    "maxIter = 300; break_limit = round(maxIter/2)\n",
    "# add samp. ratio. = .1 ---> best alpha = ?\n",
    "# add samp. ratio. = .2 ---> best alpha = ?\n",
    "# add samp. ratio. = .2 ---> best alpha = ?\n",
    "\n",
    "base = 0.05\n",
    "additional = 0.125\n",
    "\n",
    "highmask = torch.zeros((round(320*(1-base))))\n",
    "highmask[np.random.choice(round(320*(1-base)),round(320*additional),replace=False)] = 1\n",
    "\n",
    "ind = 0\n",
    "for alpha in alpha_grid:\n",
    "    print('\\n\\talpha = {}'.format(alpha))\n",
    "    highmask_refined,_ = mask_backward(highmask,xstar,\\\n",
    "                  beta=1, alpha=alpha,maxIter=maxIter,unroll_block=unroll_block,seed=0,break_limit=break_limit,\\\n",
    "                  lr=lr,mode='ADMM',Lambda=Lambda,rho=rho,\\\n",
    "                  perturb=False,perturb_freq=10,verbose=True)\n",
    "    sparsity_[ind] = mask_complete(highmask_refined.to(torch.double),320).sum().item()/320\n",
    "    change_count[ind] = torch.abs(highmask_refined - highmask).sum().item()\n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd526d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(alpha_grid,sparsity_,label='end')\n",
    "plt.scatter(alpha_grid,(base+additional)*np.ones(alpha_grid.size),label='start')\n",
    "plt.title('sparsity')\n",
    "# plt.xscale('log')\n",
    "plt.legend(bbox_to_anchor=(1.04,0.5), loc=\"center left\")\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(alpha_grid,change_count)\n",
    "# plt.xscale('log')\n",
    "plt.title('change count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514c0972",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_mloss = mask_eval(mask_complete(highmask,imgHeg,dtyp=dtyp),xstar,mode='UNET',UNET=UNET,dtyp=dtyp) * 100\n",
    "print('naive mask loss = ',naive_mloss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
